{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_preamble import *\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f'{base_dir}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = trimesh_io.MeshMeta(disk_cache_path=mesh_dir,\n",
    "                         cache_size=0, cv_path=mesh_cv_path)\n",
    "\n",
    "ais_meshes = []\n",
    "for oid in complete_ais_ids:\n",
    "    ais_file = ais_mesh_dir + '/{}_ais.h5'.format(oid)\n",
    "    if os.path.exists(ais_file):\n",
    "        ais_mesh = mm.mesh(filename=ais_file)\n",
    "        ais_meshes.append(ais_mesh)\n",
    "    else:\n",
    "        ais_meshes.append(None)\n",
    "        print('{} AIS not found!'.format(oid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudvolume as cv\n",
    "svs = cv.CloudVolume(mesh_cv_path, mip=5, bounded=False, use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudvolume as cv\n",
    "from meshparty import skeletonize\n",
    "def segmentation_mesh_zeros(mesh, dmax_vec, cv_path, mip=5, cap_y=True, use_sk=True, base_mip=0):\n",
    "    svs = cv.CloudVolume(cv_path, mip=mip, bounded=False, use_https=True)\n",
    "    print('\\tComputing grid coordinates...')\n",
    "    xmin, ymin, zmin = ((mesh.bounds[0] - max(dmax_vec)) / svs.resolution).astype(int)\n",
    "    xmax, ymax, zmax = ((mesh.bounds[1] + max(dmax_vec)) / svs.resolution).astype(int)\n",
    "    if cap_y:\n",
    "        ymin = (mesh.bounds[0][1] / svs.resolution[1]).astype(int)\n",
    "        ymax = (mesh.bounds[1][1] / svs.resolution[1]).astype(int)\n",
    "\n",
    "    X, Y, Z = np.meshgrid(np.arange(xmin, xmax), np.arange(ymin,ymax), np.arange(zmin, zmax), indexing='ij')\n",
    "\n",
    "    xyzs = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T * svs.resolution\n",
    "    if use_sk:\n",
    "        sk = skeletonize.skeletonize_mesh(mesh)\n",
    "        vert_obj = sk\n",
    "    else:\n",
    "        vert_obj = mesh\n",
    "        \n",
    "    try:\n",
    "        dsp, _ = vert_obj.pykdtree.query(xyzs, distance_upper_bound=max(dmax_vec))\n",
    "    except:\n",
    "        dsp, _ = vert_obj.kdtree.query(xyzs, distance_upper_bound=max(dmax_vec))\n",
    "\n",
    "    print('\\tDownloading segmentation...')\n",
    "\n",
    "    xslice = slice(xmin, xmax)\n",
    "    yslice = slice(ymin, ymax)\n",
    "    zslice = slice(zmin, zmax)\n",
    "    \n",
    "    sv_dat = np.squeeze(svs[xslice, yslice, zslice])\n",
    "    \n",
    "    print('\\tComputing proximate grid volume...')\n",
    "    outside_seg = (sv_dat==0).astype(int).ravel()\n",
    "    frac_out = []\n",
    "    for dmax in dmax_vec:\n",
    "        valid=dsp<dmax\n",
    "        vox_outside = np.sum(outside_seg[valid])\n",
    "        vox_total = np.sum(valid)\n",
    "        frac_out.append(vox_outside / vox_total)\n",
    "    return frac_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_version = 183\n",
    "fraction_zeros_old_df = pd.read_hdf(data_dir + '/mask_fraction_data_v{}.hdf'.format(old_version),\n",
    "                                    'mask_fraction_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmax =  [5000, 7500, 10000, 15000]\n",
    "mip=5\n",
    "cap_y=True\n",
    "f_all = {}\n",
    "for oid, ais_mesh in tqdm.tqdm(zip(complete_ais_ids, ais_meshes), total=len(ais_meshes)):\n",
    "    if np.any(fraction_zeros_old_df['root_id']==oid):\n",
    "        f = fraction_zeros_old_df[fraction_zeros_old_df['root_id']==oid].values[0,1:]\n",
    "    else:\n",
    "        f = segmentation_mesh_zeros(ais_mesh, dmax, mesh_cv_path, mip, cap_y)\n",
    "    f_all[oid] = f\n",
    "\n",
    "    \n",
    "d_dict = {k:{} for k in dmax}\n",
    "for k, x in f_all.items():\n",
    "    for ii, d in enumerate(dmax):\n",
    "        d_dict[d][k] = float(x[ii])\n",
    "\n",
    "        \n",
    "df_cols = {'d_{}'.format(d): d_dict[d] for d in dmax}\n",
    "mask_fraction_df = pd.DataFrame(df_cols).reset_index().rename(columns={'index':'root_id'})\n",
    "mask_fraction_df.to_hdf(data_dir + '/mask_fraction_data_v{}.hdf'.format(data_version),\n",
    "                        'mask_fraction_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“data_analysis”",
   "language": "python",
   "name": "jupyter_space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
