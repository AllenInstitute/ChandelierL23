{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_preamble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ais_synapse_utils import aggregate_ais_dataframes\n",
    "\n",
    "ais_synapse_filter = ais_synapse_data['d_top_skel'] < min_ais_len\n",
    "ais_synapse_data_f = ais_synapse_data[ais_synapse_filter]\n",
    "\n",
    "aggregated_ais_syn_df = aggregate_ais_dataframes(complete_ais_ids, ais_synapse_data_f)\n",
    "aggregated_ais_syn_df = aggregated_ais_syn_df[aggregated_ais_syn_df['ais_len'] >= min_ais_len].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) For each AIS and each ChC, get actual and potential connectivity table.\n",
    "\n",
    "2) For each ChC, get its actual AISes.\n",
    "\n",
    "3) For each ChC->AIS edge, get the other AISes and list the potential ChCs that also target the same original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = trimesh_io.MeshMeta(disk_cache_path=mesh_dir,\n",
    "                         cache_size=0, cv_path=mesh_cv_path, voxel_scaling=voxel_scaling)\n",
    "\n",
    "ais_meshes = {}\n",
    "for oid in complete_ais_ids:\n",
    "    ais_mesh_fname = f'{mesh_dir}/ais_meshes/{oid}_ais.h5'\n",
    "    ais_mesh = mm.mesh(filename=ais_mesh_fname)\n",
    "    ais_meshes[oid] = ais_mesh\n",
    "    \n",
    "ais_sks = []\n",
    "for oid, ais_mesh in zip(complete_ais_ids, ais_meshes):\n",
    "    ais_sk_filename = f'{skel_dir}/sk_ais_{oid}.h5'\n",
    "    sk = skeleton_io.read_skeleton_h5(ais_sk_filename)\n",
    "    sk.voxel_scaling = voxel_scaling\n",
    "    ais_sks.append(sk)\n",
    "\n",
    "soma_df = dl.query_cell_ids(soma_table)\n",
    "chc_soma_ids = soma_df['pt_root_id'][np.isin(soma_df['pt_root_id'], chc_ids)].values\n",
    "    \n",
    "chc_meshes = {}\n",
    "for oid in chc_ids:\n",
    "    if oid not in chc_soma_ids:\n",
    "        chc_mesh = mm.mesh(seg_id=oid)\n",
    "    else:\n",
    "        chc_mesh = mm.mesh(filename=mesh_dir + '/{}_axon.h5'.format(oid))\n",
    "    chc_meshes[oid] = chc_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(ais_sk.mesh_to_skel_map, np.flatnonzero(ais_sk.distance_to_root<min_ais_len))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_meshes_trunc = {}\n",
    "for ii, oid in enumerate(complete_ais_ids):\n",
    "    ais_sk = ais_sks[ii]\n",
    "    trunc_mesh = ais_meshes[oid].apply_mask(np.isin(ais_sk.mesh_to_skel_map, np.flatnonzero(ais_sk.distance_to_root<min_ais_len)))\n",
    "    ais_meshes_trunc[oid] = trunc_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "\n",
    "def potential_connection(objectA, objectB, max_distance, return_indices=False, use_pykdtree=True):\n",
    "    if isinstance(max_distance, Number):\n",
    "        if use_pykdtree is True:\n",
    "            kdtree_A = objectA.pykdtree\n",
    "            if return_indices:\n",
    "                kdtree_B = objectB.pykdtree\n",
    "        else:\n",
    "            kdtree_A = objectA.kdtree\n",
    "            if return_indices:\n",
    "                kdtree_B = objectB.kdtree\n",
    "                \n",
    "        ds, _ = kdtree_A.query(objectB.vertices, distance_upper_bound=max_distance)\n",
    "        object_b_index_mask = ds<=max_distance\n",
    "        is_close = np.any(object_b_index_mask)\n",
    "        if return_indices is False:\n",
    "            return is_close\n",
    "        else:\n",
    "            ds_BtoA, _ = kdtree_B.query(objectA.vertices, distance_upper_bound=max_distance)\n",
    "            object_a_index_mask = ds_BtoA <= max_distance\n",
    "            return is_close, object_a_index_mask, object_b_index_mask\n",
    "    else:\n",
    "        qrys = [potential_connection(objectA, objectB, max_distance=d, return_indices=return_indices, use_pykdtree=use_pykdtree) for d in max_distance]\n",
    "        if return_indices:\n",
    "            is_close_vec = np.array([q[0] for q in qrys])\n",
    "            object_a_vec = [q[1] for q in qrys]\n",
    "            object_b_vec = [q[2] for q in qrys]\n",
    "            return is_close_vec, object_a_vec, object_b_vec\n",
    "        else:\n",
    "            return np.array(qrys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_cutoff = 0.1\n",
    "mask_frac_df = pd.read_hdf(base_dir + '/data/mask_fraction_data_v{}.hdf'.format(data_version))\n",
    "ais_oid_within_limits = mask_frac_df[mask_frac_df['d_{}'.format(10000)] < fraction_cutoff]['root_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "complete_ais_ids_orig = copy.copy(complete_ais_ids)\n",
    "complete_ais_ids=np.intersect1d(complete_ais_ids, ais_oid_within_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [5000, 7500, 10000, 15000]\n",
    "\n",
    "chc_id_long = []\n",
    "ais_id_long = []\n",
    "is_close_long = []\n",
    "pbar = tqdm.tqdm(total=len(chc_ids)*len(complete_ais_ids))\n",
    "for chc_id in chc_ids:\n",
    "    for ais_id in complete_ais_ids:\n",
    "        pbar.update(1)\n",
    "        is_close = potential_connection(chc_meshes[chc_id], ais_meshes_trunc[ais_id], max_distance=ds)\n",
    "        chc_id_long.append(chc_id)\n",
    "        ais_id_long.append(ais_id)\n",
    "        is_close_long.append(is_close)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_ind = 1\n",
    "potential_df = pd.DataFrame(data={'chc_id':chc_id_long,\n",
    "                                   'ais_id':ais_id_long,\n",
    "                                   f'is_close_{ds[0]}':[x[0] for x in is_close_long],\n",
    "                                   f'is_close_{ds[1]}':[x[1] for x in is_close_long],\n",
    "                                   f'is_close_{ds[2]}':[x[2] for x in is_close_long],\n",
    "                                   })\n",
    "\n",
    "chc_to_ais_el = ais_synapse_data[['pre_pt_root_id', 'post_pt_root_id', 'is_chandelier']].query('is_chandelier==True').groupby(['pre_pt_root_id', 'post_pt_root_id']).count().reset_index()\n",
    "\n",
    "potential_df = potential_df.merge(chc_to_ais_el, how='left', left_on=['chc_id', 'ais_id'], right_on=['pre_pt_root_id', 'post_pt_root_id']).drop(columns=['pre_pt_root_id', 'post_pt_root_id'])\n",
    "potential_df = potential_df.fillna(0).rename(columns={'is_chandelier':'actual_syn'})\n",
    "\n",
    "potential_df['is_actual'] = potential_df.eval('actual_syn>0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every pair of ChCs, look for co-targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration model total counting\n",
    "\n",
    "1) For every AIS, get its potential partners\n",
    "\n",
    "2) For the real data, for all co-potentials, count the number of 0s, 1s, and 2s in ChC->AIS co-targeting.\n",
    "\n",
    "3) Make shuffled networks from the configuration model where each AIS assigns the observed number of connections to potential partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysisdatalink import connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_d = 7500\n",
    "\n",
    "dmax = rel_d\n",
    "el = connectivity.edgelist_from_synapse_df(ais_synapse_data_f.query(f'post_pt_root_id in {complete_ais_ids.tolist()}').query('is_chandelier==True'), weight_column='syn_per_edge')\n",
    "\n",
    "bipartite_actual = el.pivot_table(index='pre_pt_root_id', columns='post_pt_root_id', values='weight', fill_value=0)\n",
    "# Make sure to include cells with no ChCs\n",
    "col_ids_to_add = complete_ais_ids[~np.isin(complete_ais_ids, bipartite_actual.columns)]\n",
    "for oid in col_ids_to_add:\n",
    "    bipartite_actual[oid] = 0\n",
    "\n",
    "bipartite_potential = potential_df.pivot_table(index='chc_id', columns='ais_id', values=f'is_close_{dmax}')\n",
    "bipartite_potential_reduced = bipartite_potential.loc[bipartite_actual.index][bipartite_actual.columns]\n",
    "\n",
    "ba = bipartite_actual.values>0\n",
    "bp = bipartite_potential_reduced.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Power analysis. Take the potential graph and with some probability perturb it in favor of co-contact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "def shuffle_contact_network(ba, bp, alpha, w_cocontact, n_times=1, seed=None):\n",
    "    '''\n",
    "    Shuffle each edge with probability alpha.\n",
    "    Weight edges with previous co-contacts with weight w_cocontact (vs weight 1 for non-cocontact)\n",
    "    '''\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    ba = copy.copy(ba)\n",
    "    \n",
    "    n = 0\n",
    "    while n < n_times:\n",
    "        ais_order = np.random.permutation(np.arange(ba.shape[1]))\n",
    "        for ais_ind in ais_order:\n",
    "            chc_ind_order = np.random.permutation(np.flatnonzero(ba[:,ais_ind]))\n",
    "            for chc_ind in chc_ind_order:\n",
    "                # Do shuffle\n",
    "                if np.random.rand() < alpha:\n",
    "                    # Remove edge\n",
    "                    ba[chc_ind, ais_ind] = False\n",
    "\n",
    "                    # Get potential ChCs\n",
    "                    actual_chc_inds = np.flatnonzero(ba[:,ais_ind])\n",
    "                    potential_chc_inds = np.setdiff1d(np.flatnonzero(bp[:, ais_ind]), actual_chc_inds)\n",
    "\n",
    "                    # Which chcs are co-contacts?\n",
    "                    cocontact_ais_inds = np.setdiff1d(np.flatnonzero(np.sum(ba[actual_chc_inds,:], axis=0)>0), [ais_ind])\n",
    "                    cocontact_options = np.flatnonzero(ba[potential_chc_inds][:, cocontact_ais_inds].sum(axis=1)>0)\n",
    "\n",
    "                    choice_weights = np.ones(len(potential_chc_inds))\n",
    "                    choice_weights[cocontact_options] = w_cocontact\n",
    "\n",
    "                    new_chc_ind = np.random.choice(potential_chc_inds, p=choice_weights/np.sum(choice_weights))\n",
    "                    ba[new_chc_ind, ais_ind] = True\n",
    "        n = n+1\n",
    "    return ba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotarget_motif_type2(ba, bp):\n",
    "    is_cotarget_motif = []\n",
    "    is_cotarget_motif_actual = []\n",
    "    for ais_ind in range(ba.shape[1]):\n",
    "        is_cotarget_motif.append(0)\n",
    "        is_cotarget_motif_actual.append(0)\n",
    "        actual_chc_inds = np.flatnonzero(ba[:, ais_ind])\n",
    "        potential_chc_inds = np.flatnonzero(bp[:, ais_ind])\n",
    "        for chc_ind in potential_chc_inds:\n",
    "            my_other_ais_inds = np.setdiff1d(np.flatnonzero(ba[chc_ind, :]), [ais_ind])\n",
    "            other_chc_inds = np.setdiff1d(actual_chc_inds, [chc_ind])\n",
    "            for other_chc_ind in other_chc_inds:\n",
    "                their_other_ais_inds = np.setdiff1d(np.flatnonzero(ba[other_chc_ind, :]), [ais_ind])\n",
    "                if np.any(np.isin(my_other_ais_inds, their_other_ais_inds)):\n",
    "                    is_cotarget_motif[-1] += 1\n",
    "                    if chc_ind in actual_chc_inds:\n",
    "                        is_cotarget_motif_actual[-1] += 1\n",
    "    return is_cotarget_motif, is_cotarget_motif_actual, sum(is_cotarget_motif_actual)/sum(is_cotarget_motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cotarget_motif, is_cotarget_motif_actual, cotarget_fraction_observed = cotarget_motif_type2(ba, bp)\n",
    "p_doublet_observed = cotarget_fraction\n",
    "print(p_doublet_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiwrapper.multiprocessing_utils as mu\n",
    "\n",
    "def _multi_shuffle(data):\n",
    "    ba, bp, alpha, n_times, seed = data\n",
    "    new_ba = shuffle_contact_network(ba, bp, 1, alpha, n_times, seed=None)\n",
    "    _, _, cotarget_fraction = cotarget_motif_type2(new_ba, bp)\n",
    "    return cotarget_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "alphas = np.arange(0.1, 2.51, 0.1)\n",
    "n_times = 5\n",
    "\n",
    "cotarget_fraction_moved = []\n",
    "for alpha in tqdm.tqdm(alphas):\n",
    "    seeds = np.random.randint(0, 10000000, size=N)\n",
    "    data = []\n",
    "    for ii in range(N):\n",
    "        data.append((ba, bp, alpha, n_times, seeds[ii]))\n",
    "    shuffled_fractions = mu.multiprocess_func(_multi_shuffle, data)\n",
    "    cotarget_fraction_moved.append(shuffled_fractions)\n",
    "\n",
    "data_df = pd.DataFrame(data={alphas[ii]:cts for ii, cts in enumerate(cotarget_fraction_moved)})\n",
    "comp_df = data_df.unstack().reset_index().rename(columns={'level_0':'alpha', 0:'MotifConnectionProb'}).drop(columns=['level_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2,1), dpi=300)\n",
    "sns.violinplot(ax=ax, x='alpha', y='MotifConnectionProb',\n",
    "               inner=None, linewidth=0.1, width=0.9, color=non_color,\n",
    "               data=comp_df)\n",
    "ax.hlines(xmin=-1, xmax=len(alphas), y=cotarget_fraction_observed, color=chc_color, linestyle='--', linewidth=0.75)\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_xticks(np.arange(1,len(alphas),2))\n",
    "ax.set_yticks(np.arange(0.25, 0.5, 0.05))\n",
    "ax.set_ylabel('Motif Connection Prob.')\n",
    "ax.set_xlim(-1, len(alphas))\n",
    "sns.despine(ax=ax, offset=4)\n",
    "set_axis_fonts(ax, tick_font={'size':5}, label_font={'size':5}, yprecision=2)\n",
    "# _=ax.set_xticklabels([f'{al:.1f}' if np.mod(ii,2)==1 else '' for ii, al in enumerate(alphas)])\n",
    "_=ax.set_xticklabels([f'{al:.1f}' for ii, al in enumerate(alphas[1::2])])\n",
    "\n",
    "ps = []\n",
    "pso = []\n",
    "for cf in cotarget_fraction_moved:\n",
    "    ps.append(np.sum(np.array(cf)<cotarget_fraction_observed) / len(cf))\n",
    "    pso.append(np.sum(np.array(cf)>cotarget_fraction_observed) / len(cf))\n",
    "\n",
    "n_stars = np.full(len(alphas), 0)\n",
    "n_stars[np.logical_or( np.array(ps)<0.05, np.array(pso)<0.05)] = 1\n",
    "star_ys=[np.percentile(cm, 95) for cm in cotarget_fraction_moved]\n",
    "plot_stars(np.arange(0, len(alphas)), star_ys, n_stars, ax=ax, xytext=(0,8), fontsize=4, color=chc_color, horizontalalignment='center')\n",
    "\n",
    "fig.savefig(f'{plot_dir}/power_analysis_panel.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_rand_ind = np.flatnonzero(np.array(alphas)==1)[0]\n",
    "\n",
    "figsize = (1,1)\n",
    "dpi = 300\n",
    "fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "bary, barx = np.histogram(cotarget_fraction_moved[flat_rand_ind], bins=20)\n",
    "ax.bar(barx[:-1], bary/np.sum(bary), color=non_color, width=np.mean(np.diff(barx)), linewidth=0.25, align='edge')\n",
    "ax.vlines(x=cotarget_fraction_observed, ymin=0, ymax=max(bary/np.sum(bary)+0.015), color=chc_color, linewidth=1.5 )\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Motif Connection Prob.')\n",
    "ax.set_xticks(np.arange(0.35, 0.45, 0.05))\n",
    "sns.despine(ax=ax, offset=3)\n",
    "set_axis_fonts(ax, tick_font={'size':5, 'color':'k'}, xprecision=2, yprecision=2, label_font={'size':5, 'color':'k'})\n",
    "\n",
    "# fig.savefig(f'{plot_dir}/motif_analysis_randomized.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_d = 5000\n",
    "N = 1000\n",
    "\n",
    "dmax = rel_d\n",
    "el = connectivity.edgelist_from_synapse_df(ais_synapse_data_f.query(f'post_pt_root_id in {complete_ais_ids.tolist()}').query('is_chandelier==True'), weight_column='syn_per_edge')\n",
    "\n",
    "bipartite_actual = el.pivot_table(index='pre_pt_root_id', columns='post_pt_root_id', values='weight', fill_value=0)\n",
    "# Make sure to include cells with no ChCs\n",
    "col_ids_to_add = complete_ais_ids[~np.isin(complete_ais_ids, bipartite_actual.columns)]\n",
    "for oid in col_ids_to_add:\n",
    "    bipartite_actual[oid] = 0\n",
    "\n",
    "bipartite_potential = potential_df.pivot_table(index='chc_id', columns='ais_id', values=f'is_close_{dmax}')\n",
    "bipartite_potential_reduced = bipartite_potential.loc[bipartite_actual.index][bipartite_actual.columns]\n",
    "\n",
    "ba = bipartite_actual.values>0\n",
    "bp = bipartite_potential_reduced.values.astype(int)\n",
    "\n",
    "is_cotarget_motif, is_cotarget_motif_actual, cotarget_fraction_observed = cotarget_motif_type2(ba, bp)\n",
    "\n",
    "##########\n",
    "\n",
    "alphas = np.arange(0.1, 2.51, 0.1)\n",
    "n_times = 5\n",
    "\n",
    "cotarget_fraction_moved = []\n",
    "for alpha in tqdm.tqdm(alphas):\n",
    "    seeds = np.random.randint(0, 10000000, size=N)\n",
    "    data = []\n",
    "    for ii in range(N):\n",
    "        data.append((ba, bp, alpha, n_times, seeds[ii]))\n",
    "    shuffled_fractions = mu.multiprocess_func(_multi_shuffle, data)\n",
    "    cotarget_fraction_moved.append(shuffled_fractions)\n",
    "\n",
    "data_df = pd.DataFrame(data={alphas[ii]:cts for ii, cts in enumerate(cotarget_fraction_moved)})\n",
    "comp_df = data_df.unstack().reset_index().rename(columns={'level_0':'alpha', 0:'MotifConnectionProb'}).drop(columns=['level_1'])\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_rand_ind = np.flatnonzero(np.array(alphas)==1)[0]\n",
    "\n",
    "figsize = (1,1)\n",
    "dpi = 300\n",
    "fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "bary, barx = np.histogram(cotarget_fraction_moved[flat_rand_ind], bins=20)\n",
    "ax.bar(barx[:-1], bary/np.sum(bary), color=non_color, width=np.mean(np.diff(barx)), linewidth=0.25, align='edge')\n",
    "ax.vlines(x=cotarget_fraction_observed, ymin=0, ymax=max(bary/np.sum(bary)+0.015), color=chc_color, linewidth=1.5 )\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Motif Connection Prob.')\n",
    "ax.set_xticks(np.arange(0.35, 0.45, 0.05))\n",
    "sns.despine(ax=ax, offset=3)\n",
    "set_axis_fonts(ax, tick_font={'size':5, 'color':'k'}, xprecision=2, yprecision=2, label_font={'size':5, 'color':'k'})\n",
    "\n",
    "# fig.savefig(f'{plot_dir}/motif_analysis_randomized_{rel_d}.pdf', bbox_inches='tight')\n",
    "\n",
    "####\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,1), dpi=300)\n",
    "sns.violinplot(ax=ax, x='alpha', y='MotifConnectionProb',\n",
    "               inner=None, linewidth=0.1, width=0.9, color=non_color,\n",
    "               data=comp_df)\n",
    "ax.hlines(xmin=-1, xmax=len(alphas), y=cotarget_fraction_observed, color=chc_color, linestyle='--', linewidth=0.75)\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_xticks(np.arange(1,len(alphas),2))\n",
    "ax.set_yticks(np.arange(0.25, 0.5, 0.05))\n",
    "ax.set_ylabel('Motif Connection Prob.')\n",
    "ax.set_xlim(-1, len(alphas))\n",
    "sns.despine(ax=ax, offset=4)\n",
    "set_axis_fonts(ax, tick_font={'size':5}, label_font={'size':5}, yprecision=2)\n",
    "# _=ax.set_xticklabels([f'{al:.1f}' if np.mod(ii,2)==1 else '' for ii, al in enumerate(alphas)])\n",
    "_=ax.set_xticklabels([f'{al:.1f}' for ii, al in enumerate(alphas[1::2])])\n",
    "\n",
    "ps = []\n",
    "pso = []\n",
    "for cf in cotarget_fraction_moved:\n",
    "    ps.append(np.sum(np.array(cf)<cotarget_fraction_observed) / len(cf))\n",
    "    pso.append(np.sum(np.array(cf)>cotarget_fraction_observed) / len(cf))\n",
    "\n",
    "n_stars = np.full(len(alphas), 0)\n",
    "n_stars[np.logical_or( np.array(ps)<0.05, np.array(pso)<0.05)] = 1\n",
    "star_ys=[np.percentile(cm, 95) for cm in cotarget_fraction_moved]\n",
    "plot_stars(np.arange(0, len(alphas)), star_ys, n_stars, ax=ax, xytext=(0,8), fontsize=4, color=chc_color, horizontalalignment='center')\n",
    "\n",
    "# fig.savefig(f'{plot_dir}/power_analysis_panel_{rel_d}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_d = 10000\n",
    "N = 1000\n",
    "\n",
    "dmax = rel_d\n",
    "el = connectivity.edgelist_from_synapse_df(ais_synapse_data_f.query(f'post_pt_root_id in {complete_ais_ids.tolist()}').query('is_chandelier==True'), weight_column='syn_per_edge')\n",
    "\n",
    "bipartite_actual = el.pivot_table(index='pre_pt_root_id', columns='post_pt_root_id', values='weight', fill_value=0)\n",
    "# Make sure to include cells with no ChCs\n",
    "col_ids_to_add = complete_ais_ids[~np.isin(complete_ais_ids, bipartite_actual.columns)]\n",
    "for oid in col_ids_to_add:\n",
    "    bipartite_actual[oid] = 0\n",
    "\n",
    "bipartite_potential = potential_df.pivot_table(index='chc_id', columns='ais_id', values=f'is_close_{dmax}')\n",
    "bipartite_potential_reduced = bipartite_potential.loc[bipartite_actual.index][bipartite_actual.columns]\n",
    "\n",
    "ba = bipartite_actual.values>0\n",
    "bp = bipartite_potential_reduced.values.astype(int)\n",
    "\n",
    "is_cotarget_motif, is_cotarget_motif_actual, cotarget_fraction_observed = cotarget_motif_type2(ba, bp)\n",
    "\n",
    "##########\n",
    "\n",
    "alphas = np.arange(0.1, 2.51, 0.1)\n",
    "n_times = 5\n",
    "\n",
    "cotarget_fraction_moved = []\n",
    "for alpha in tqdm.tqdm(alphas):\n",
    "    seeds = np.random.randint(0, 10000000, size=N)\n",
    "    data = []\n",
    "    for ii in range(N):\n",
    "        data.append((ba, bp, alpha, n_times, seeds[ii]))\n",
    "    shuffled_fractions = mu.multiprocess_func(_multi_shuffle, data)\n",
    "    cotarget_fraction_moved.append(shuffled_fractions)\n",
    "\n",
    "data_df = pd.DataFrame(data={alphas[ii]:cts for ii, cts in enumerate(cotarget_fraction_moved)})\n",
    "comp_df = data_df.unstack().reset_index().rename(columns={'level_0':'alpha', 0:'MotifConnectionProb'}).drop(columns=['level_1'])\n",
    "\n",
    "####\n",
    "\n",
    "flat_rand_ind = np.flatnonzero(np.array(alphas)==1)[0]\n",
    "\n",
    "figsize = (1,1)\n",
    "dpi = 300\n",
    "fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "bary, barx = np.histogram(cotarget_fraction_moved[flat_rand_ind], bins=20)\n",
    "ax.bar(barx[:-1], bary/np.sum(bary), color=non_color, width=np.mean(np.diff(barx)), linewidth=0.25, align='edge')\n",
    "ax.vlines(x=cotarget_fraction_observed, ymin=0, ymax=max(bary/np.sum(bary)+0.015), color=chc_color, linewidth=1.5 )\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Motif Connection Prob.')\n",
    "ax.set_xticks(np.arange(0.35, 0.45, 0.05))\n",
    "sns.despine(ax=ax, offset=3)\n",
    "set_axis_fonts(ax, tick_font={'size':5, 'color':'k'}, xprecision=2, yprecision=2, label_font={'size':5, 'color':'k'})\n",
    "\n",
    "fig.savefig(f'{plot_dir}/motif_analysis_randomized_{rel_d}.pdf', bbox_inches='tight')\n",
    "\n",
    "####\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,1), dpi=300)\n",
    "sns.violinplot(ax=ax, x='alpha', y='MotifConnectionProb',\n",
    "               inner=None, linewidth=0.1, width=0.9, color=non_color,\n",
    "               data=comp_df)\n",
    "ax.hlines(xmin=-1, xmax=len(alphas), y=cotarget_fraction_observed, color=chc_color, linestyle='--', linewidth=0.75)\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_xticks(np.arange(1,len(alphas),2))\n",
    "ax.set_yticks(np.arange(0.25, 0.5, 0.05))\n",
    "ax.set_ylabel('Motif Connection Prob.')\n",
    "ax.set_xlim(-1, len(alphas))\n",
    "sns.despine(ax=ax, offset=4)\n",
    "set_axis_fonts(ax, tick_font={'size':5}, label_font={'size':5}, yprecision=2)\n",
    "# _=ax.set_xticklabels([f'{al:.1f}' if np.mod(ii,2)==1 else '' for ii, al in enumerate(alphas)])\n",
    "_=ax.set_xticklabels([f'{al:.1f}' for ii, al in enumerate(alphas[1::2])])\n",
    "\n",
    "ps = []\n",
    "pso = []\n",
    "for cf in cotarget_fraction_moved:\n",
    "    ps.append(np.sum(np.array(cf)<cotarget_fraction_observed) / len(cf))\n",
    "    pso.append(np.sum(np.array(cf)>cotarget_fraction_observed) / len(cf))\n",
    "\n",
    "n_stars = np.full(len(alphas), 0)\n",
    "n_stars[np.logical_or( np.array(ps)<0.05, np.array(pso)<0.05)] = 1\n",
    "star_ys=[np.percentile(cm, 95) for cm in cotarget_fraction_moved]\n",
    "plot_stars(np.arange(0, len(alphas)), star_ys, n_stars, ax=ax, xytext=(0,8), fontsize=4, color=chc_color, horizontalalignment='center')\n",
    "\n",
    "fig.savefig(f'{plot_dir}/power_analysis_panel_{rel_d}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotarget_fraction_observed_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import bicluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import bicluster\n",
    "sco = bicluster.SpectralCoclustering(n_clusters=3)\n",
    "\n",
    "sco_res = sco.fit(bp)\n",
    "\n",
    "newrow = np.argsort(sco_res.row_labels_)\n",
    "newcol = np.argsort(sco_res.column_labels_)\n",
    "plt.imshow(1-bp[:,newcol][newrow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_d = 7500\n",
    "\n",
    "dmax = rel_d\n",
    "el = connectivity.edgelist_from_synapse_df(ais_synapse_data_f.query(f'post_pt_root_id in {complete_ais_ids.tolist()}').query('is_chandelier==True'), weight_column='syn_per_edge')\n",
    "\n",
    "bipartite_actual = el.pivot_table(index='pre_pt_root_id', columns='post_pt_root_id', values='weight', fill_value=0)\n",
    "# Make sure to include cells with no ChCs\n",
    "col_ids_to_add = complete_ais_ids[~np.isin(complete_ais_ids, bipartite_actual.columns)]\n",
    "for oid in col_ids_to_add:\n",
    "    bipartite_actual[oid] = 0\n",
    "\n",
    "bipartite_potential = potential_df.pivot_table(index='chc_id', columns='ais_id', values=f'is_close_{dmax}')\n",
    "bipartite_potential_reduced = bipartite_potential.loc[bipartite_actual.index][bipartite_actual.columns]\n",
    "\n",
    "ba = bipartite_actual.values>0\n",
    "bp = bipartite_potential_reduced.values.astype(int)\n",
    "\n",
    "###\n",
    "\n",
    "from sklearn.cluster import bicluster\n",
    "sco = bicluster.SpectralCoclustering(n_clusters=4)\n",
    "\n",
    "sco_res = sco.fit(bp)\n",
    "\n",
    "newrow = np.argsort(sco_res.row_labels_)\n",
    "newcol = np.argsort(sco_res.column_labels_)\n",
    "\n",
    "###\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1,1), dpi=300)\n",
    "\n",
    "yps, xps = np.where(bp[:,newcol][newrow])\n",
    "ax.plot(xps, yps, 'k.', markersize=2, alpha=0.8, markeredgewidth=0)\n",
    "\n",
    "yas, xas = np.where(ba[:,newcol][newrow])\n",
    "ax.plot(xas, yas, '.', markersize=2, color=chc_color, alpha=1,\n",
    "        markeredgewidth=0)\n",
    "\n",
    "ax.set_xlabel('PyCs')\n",
    "ax.set_ylabel('ChCs')\n",
    "ax.set_xticks([0,100])\n",
    "ax.set_yticks([0,100])\n",
    "sns.despine(ax=ax)\n",
    "set_axis_fonts(ax=ax, tick_font={'size':5}, xtick_int=True, ytick_int=True, label_font={'size':5})\n",
    "\n",
    "fig.savefig(f'{plot_dir}/adjmat_chc_pyc_potential_7500.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_d = 5000\n",
    "\n",
    "dmax = rel_d\n",
    "\n",
    "bipartite_potential = potential_df.pivot_table(index='chc_id', columns='ais_id', values=f'is_close_{dmax}')\n",
    "bipartite_potential_reduced = bipartite_potential.loc[bipartite_actual.index][bipartite_actual.columns]\n",
    "bp = bipartite_potential_reduced.values.astype(int)\n",
    "\n",
    "###\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1,1), dpi=300)\n",
    "\n",
    "yps, xps = np.where(bp[:,newcol][newrow])\n",
    "ax.plot(xps, yps, 'k.', markersize=2, markeredgewidth=0)\n",
    "\n",
    "yas, xas = np.where(ba[:,newcol][newrow])\n",
    "ax.plot(xas, yas, '.', markersize=2, color=chc_color, markeredgewidth=0)\n",
    "\n",
    "ax.set_xlabel('PyCs')\n",
    "ax.set_ylabel('ChCs')\n",
    "ax.set_xticks([0,100])\n",
    "ax.set_yticks([0,100])\n",
    "sns.despine(ax=ax)\n",
    "set_axis_fonts(ax=ax, tick_font={'size':5}, xtick_int=True, ytick_int=True, label_font={'size':5})\n",
    "\n",
    "fig.savefig(f'{plot_dir}/adjmat_chc_pyc_potential_5000.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_d = 10000\n",
    "\n",
    "dmax = rel_d\n",
    "el = connectivity.edgelist_from_synapse_df(ais_synapse_data_f.query(f'post_pt_root_id in {complete_ais_ids.tolist()}').query('is_chandelier==True'), weight_column='syn_per_edge')\n",
    "\n",
    "bipartite_actual = el.pivot_table(index='pre_pt_root_id', columns='post_pt_root_id', values='weight', fill_value=0)\n",
    "# Make sure to include cells with no ChCs\n",
    "col_ids_to_add = complete_ais_ids[~np.isin(complete_ais_ids, bipartite_actual.columns)]\n",
    "for oid in col_ids_to_add:\n",
    "    bipartite_actual[oid] = 0\n",
    "\n",
    "bipartite_potential = potential_df.pivot_table(index='chc_id', columns='ais_id', values=f'is_close_{dmax}')\n",
    "bipartite_potential_reduced = bipartite_potential.loc[bipartite_actual.index][bipartite_actual.columns]\n",
    "\n",
    "ba = bipartite_actual.values>0\n",
    "bp = bipartite_potential_reduced.values.astype(int)\n",
    "\n",
    "###\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1,1), dpi=300)\n",
    "\n",
    "yps, xps = np.where(bp[:,newcol][newrow])\n",
    "ax.plot(xps, yps, 'k.', markersize=2, markeredgewidth=0)\n",
    "\n",
    "yas, xas = np.where(ba[:,newcol][newrow])\n",
    "ax.plot(xas, yas, '.', markersize=2, color=chc_color, markeredgewidth=0)\n",
    "\n",
    "ax.set_xlabel('PyCs')\n",
    "ax.set_ylabel('ChCs')\n",
    "ax.set_xticks([0,100])\n",
    "ax.set_yticks([0,100])\n",
    "sns.despine(ax=ax)\n",
    "set_axis_fonts(ax=ax, tick_font={'size':5}, xtick_int=True, ytick_int=True, label_font={'size':5})\n",
    "\n",
    "fig.savefig(f'{plot_dir}/adjmat_chc_pyc_potential_{rel_d}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(1-ba[:,neword][newrow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.sum() / bp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chc_el = connectivity.edgelist_from_synapse_df(ais_synapse_data.query('is_chandelier==True'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chc_syn = aggregated_ais_syn_df['syn_net_chc'].values\n",
    "num_cells = aggregated_ais_syn_df['num_cells_chc'].values\n",
    "connection_weights = chc_el['weight'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
