{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/caseys/Work/data_analysis/ais_analysis_pipeline/data/in/data_v185_ais_bounds_v3_is_chandelier_v5.h5\n",
      "\n",
      "\n",
      "Warning: 1 oids failed on AIS synapse computation\n",
      "Minimum AIS length: 37187.05055806807\n"
     ]
    }
   ],
   "source": [
    "from common_preamble import *\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = plot_dir + '/truncated_alt'\n",
    "if not os.path.exists(plot_dir):\n",
    "    print('Making new truncated plot directory...')\n",
    "    os.mkdir(plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the AIS length to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tComputing aggregate AIS information\n"
     ]
    }
   ],
   "source": [
    "from ais_synapse_utils import aggregate_ais_dataframes\n",
    "complete_ais_ids = np.unique(ais_synapse_data['post_pt_root_id'])\n",
    "ais_id_to_analyze = np.unique(ais_synapse_data['post_pt_root_id'])\n",
    "\n",
    "ais_synapse_filter = ais_synapse_data['d_top_skel'] < min_ais_len\n",
    "ais_synapse_data_f = ais_synapse_data[ais_synapse_filter]\n",
    "\n",
    "aggregated_ais_syn_df = aggregate_ais_dataframes(complete_ais_ids, ais_synapse_data_f)\n",
    "aggregated_ais_syn_df = aggregated_ais_syn_df[aggregated_ais_syn_df['ais_len'] >= min_ais_len].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'soma_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/analysis/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'soma_position'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d0030c5a4700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#                                                     how='left', left_on='post_pt_root_id', right_on='pt_root_id').drop(columns=('pt_root_id'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msoma_to_null\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregated_ais_syn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'soma_position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoma_to_null\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maggregated_ais_syn_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'soma_position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/analysis/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/analysis/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'soma_position'"
     ]
    }
   ],
   "source": [
    "in_analysis_set = np.isin(aggregated_ais_syn_df['post_pt_root_id'], list(ais_id_to_analyze))\n",
    "aggregated_ais_syn_df = aggregated_ais_syn_df[in_analysis_set]\n",
    "\n",
    "sv_df = dl.query_cell_types('soma_valence')\n",
    "aggregated_ais_syn_df = aggregated_ais_syn_df.merge(sv_df[['pt_root_id', 'pt_position']].rename(columns={'pt_position':'soma_position'}),\n",
    "                                                    how='left', left_on='post_pt_root_id', right_on='pt_root_id').drop(columns=('pt_root_id'))\n",
    "\n",
    "soma_to_null = aggregated_ais_syn_df['soma_position'].map(lambda x: np.all(np.isnan(x)))\n",
    "for ii in np.flatnonzero(soma_to_null):\n",
    "    aggregated_ais_syn_df.at[ii, 'soma_position'] = np.full(3, np.nan)\n",
    "    \n",
    "aggregated_ais_syn_df['soma_x'] = np.vstack(aggregated_ais_syn_df['soma_position'].values)[:,0] * 4\n",
    "aggregated_ais_syn_df['soma_y'] = np.vstack(aggregated_ais_syn_df['soma_position'].values)[:,1] * 4\n",
    "aggregated_ais_syn_df['soma_z'] = np.vstack(aggregated_ais_syn_df['soma_position'].values)[:,2] * 40\n",
    "\n",
    "aggregated_ais_syn_df['soma_x_um'] = np.vstack(aggregated_ais_syn_df['soma_position'].values)[:,0] * 4 / 1000\n",
    "aggregated_ais_syn_df['soma_y_um'] = np.vstack(aggregated_ais_syn_df['soma_position'].values)[:,1] * 4 / 1000\n",
    "aggregated_ais_syn_df['soma_z_um'] = np.vstack(aggregated_ais_syn_df['soma_position'].values)[:,2] * 40 / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all synapses from AIS-targeting neurons onto our neurons in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_syn_filename = base_dir + '/data/in/all_synapses_onto_pycs_v{}.h5'.format(data_version)\n",
    "if os.path.exists(all_syn_filename):\n",
    "    all_post_synapses_df = pd.read_hdf(all_syn_filename, 'all_post_synapses_df')\n",
    "else:\n",
    "    syn_dfs = []\n",
    "    for oid in tqdm.tqdm(np.unique(aggregated_ais_syn_df['post_pt_root_id'])):\n",
    "        syn_dfs.append(dl.query_synapses(synapse_table, post_ids=[oid]))\n",
    "    all_post_synapses_df = pd.concat(syn_dfs)\n",
    "    all_post_synapses_df.to_hdf(all_syn_filename, 'all_post_synapses_df')\n",
    "all_post_synapses_dec_df = all_post_synapses_df.merge(ais_synapse_data[['id', 'is_chandelier']], how='left', on='id')\n",
    "non_ais_post_syns = all_post_synapses_dec_df[all_post_synapses_dec_df['is_chandelier'].map(np.isnan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f356ee2fc483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_soma_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_cell_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ais_analysis_soma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pt_root_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marbor_ais_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregated_ais_syn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregated_ais_syn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'post_pt_root_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_soma_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dl' is not defined"
     ]
    }
   ],
   "source": [
    "full_soma_ids = dl.query_cell_ids('ais_analysis_soma')['pt_root_id'].values\n",
    "arbor_ais_df = aggregated_ais_syn_df[np.isin(aggregated_ais_syn_df['post_pt_root_id'], full_soma_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Boutique soma fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_version = 174\n",
    "data_dir = base_dir + '/data/in'\n",
    "soma_filename = data_dir + '/soma_metrics_v{}.h5'.format(original_data_version)\n",
    "\n",
    "if os.path.exists(soma_filename):\n",
    "    soma_synapse_df = pd.read_hdf(soma_filename, 'soma_metrics')\n",
    "else:\n",
    "    print('No soma data for this version!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_df = dl.query_cell_types(soma_table)\n",
    "\n",
    "curr_root_ids = []\n",
    "for _, row in soma_synapse_df.iterrows():\n",
    "    curr_root_id = soma_df[soma_df['id']==row['id_soma']]['pt_root_id'].values[0]\n",
    "    curr_root_ids.append(curr_root_id)\n",
    "soma_synapse_df['curr_root_id'] = curr_root_ids\n",
    "\n",
    "rel_columns = ['curr_root_id', 'label', 'mean_soma_syn_size', 'soma_area', 'soma_synapses', 'soma_syn_density']\n",
    "arbor_ais_df = arbor_ais_df.merge(soma_synapse_df[rel_columns], how='left', left_on='post_pt_root_id', right_on='curr_root_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2,2))\n",
    "row_filter = arbor_ais_df['label']>1\n",
    "sns.scatterplot(x='soma_synapses', y='soma_syn_density', data=arbor_ais_df[row_filter], ax=ax, color='k', alpha=0.5)\n",
    "ax.set_xlabel('# Soma Syn.')\n",
    "ax.set_ylabel('# Soma Syn./Soma Area ($\\mu m^2$)')\n",
    "sns.despine(ax=ax, offset=5)\n",
    "fig.savefig(plot_dir + '/soma_syn_vs_soma_syn_density.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df['syn_net_chc'].std() / arbor_ais_df['syn_net_chc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df['soma_synapses'].std() / arbor_ais_df['soma_synapses'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df['syn_net_chc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df['soma_synapses'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rtrans = np.load(base_dir + '/data/in/pinky_rotation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_position_orig = np.vstack(arbor_ais_df['soma_position'].values) * voxel_resolution\n",
    "soma_position_rot = np.dot(Rtrans, soma_position_orig.T).T\n",
    "rot_offset = np.min(soma_position_rot, axis=0)\n",
    "soma_position_rot = soma_position_rot - rot_offset\n",
    "\n",
    "arbor_ais_df['soma_position_rot'] = [xyz for xyz in soma_position_rot]\n",
    "arbor_ais_df['soma_x'] = soma_position_rot[:,0]\n",
    "arbor_ais_df['soma_y'] = soma_position_rot[:,1]\n",
    "arbor_ais_df['soma_z'] = soma_position_rot[:,2]\n",
    "\n",
    "arbor_ais_df['soma_x_um'] = soma_position_rot[:,0] / 1000\n",
    "arbor_ais_df['soma_y_um'] = soma_position_rot[:,1] / 1000\n",
    "arbor_ais_df['soma_z_um'] = soma_position_rot[:,2] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Get AIS radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from meshparty import skeletonize, skeleton_io\n",
    "\n",
    "mm = trimesh_io.MeshMeta(disk_cache_path=mesh_dir,\n",
    "                         cache_size=0, cv_path=mesh_cv_path, voxel_scaling=voxel_scaling)\n",
    "\n",
    "ais_meshes = []\n",
    "for oid in complete_ais_ids:\n",
    "    ais_file = ais_mesh_dir + '/{}_ais.h5'.format(oid)\n",
    "    if os.path.exists(ais_file):\n",
    "        ais_mesh = mm.mesh(filename=ais_file)\n",
    "        ais_meshes.append(ais_mesh)\n",
    "    else:\n",
    "        ais_meshes.append(None)\n",
    "        print('{} AIS not found!'.format(oid))\n",
    "\n",
    "data_dir = base_dir + '/data'\n",
    "\n",
    "ais_sks = []\n",
    "for oid, ais_mesh in zip(complete_ais_ids, ais_meshes):\n",
    "    ais_sk_filename = skel_dir + '/sk_ais_{}.h5'.format(oid)\n",
    "    if os.path.exists(ais_sk_filename):\n",
    "        ais_sks.append(skeleton_io.read_skeleton_h5(ais_sk_filename))\n",
    "    else:\n",
    "        ais_sk = skeletonize.skeletonize_mesh(ais_mesh )\n",
    "        ais_sks.append(ais_sk)\n",
    "        skeleton_io.write_skeleton_h5(ais_sk, ais_sk_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, inds = ais_meshes[0].kdtree.query( ais_sks[0].vertices )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshparty import ray_tracing\n",
    "ais_rad = []\n",
    "for m, sk in zip(ais_meshes, ais_sks):\n",
    "    d, inds = m.kdtree.query( sk.vertices )\n",
    "    rs = ray_tracing.ray_trace_distance(inds, m)\n",
    "    ds = sk.distance_to_root\n",
    "    med_r = np.nanmedian(rs[ np.logical_and(ds>initial_cutoff_length, ds<min_ais_len)])/2\n",
    "    ais_rad.append(med_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cutoff_length = 5000\n",
    "ais_radius = []\n",
    "for ais_sk in ais_sks:\n",
    "    rs= np.array(ais_sk.vertex_properties['rs'][:-1])\n",
    "    ais_radius.append(np.nanmedian(rs[np.logical_and(ais_sk.distance_to_root< min_ais_len, ais_sk.distance_to_root>initial_cutoff_length)])/2)\n",
    "ais_radius_df = pd.DataFrame(data={'post_pt_root_id': complete_ais_ids, 'ais_radius': ais_radius})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df = arbor_ais_df.merge(ais_radius_df, on='post_pt_root_id')\n",
    "plot_label_lookup['ais_radius'] = 'AIS radius (nm)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chc_syn_df = dl.query_synapses(synapse_table, pre_ids=chc_ids)\n",
    "nonchc_syn_df = dl.query_synapses(synapse_table, pre_ids=np.unique(ais_synapse_data.query('is_chandelier==False')['pre_pt_root_id']))\n",
    "\n",
    "chc_syn_loc = np.vstack(chc_syn_df['ctr_pt_position'].values) * voxel_resolution\n",
    "nonchc_syn_loc = np.vstack(nonchc_syn_df['ctr_pt_position'].values) * voxel_resolution\n",
    "\n",
    "chc_syn_loc_rot = np.dot(Rtrans, chc_syn_loc.T).T - rot_offset\n",
    "nonchc_syn_loc_rot = np.dot(Rtrans, nonchc_syn_loc.T).T - rot_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwidth = 20\n",
    "bins = np.arange(-40, 200, bwidth)\n",
    "chc_depth_ct, _ = np.histogram(chc_syn_loc_rot[:,1] / 1000, bins=bins)\n",
    "non_depth_ct, _ = np.histogram(nonchc_syn_loc_rot[:,1] / 1000, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,8)\n",
    "\n",
    "alldat = np.concatenate((soma_position_rot, chc_syn_loc_rot, nonchc_syn_loc_rot)) / 1000\n",
    "xax_min, yax_min, zax_min = np.min(alldat, axis=0).tolist()\n",
    "xax_max, yax_max, zax_max = np.max(alldat, axis=0).tolist()\n",
    "hull_x, hull_y = convex_hull_xy(alldat[:, [0,1]])\n",
    "\n",
    "yticks = np.arange(0,161,20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.plot(nonchc_syn_loc_rot[:,0]/1000, nonchc_syn_loc_rot[:, 1]/1000, marker='.', linestyle='none', color=non_color, alpha=0.01)\n",
    "ax.plot(hull_x, hull_y, color=non_color, alpha=0.5)\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([xax_min, xax_max])\n",
    "ax.set_ylim([yax_min, yax_max])\n",
    "ax.set_yticks(yticks)\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Non-ChC Synapses (n={})'.format(len(nonchc_syn_loc_rot)))\n",
    "sns.despine(offset=5, ax=ax, trim=True)\n",
    "fig.savefig(fname=plot_dir+'/synapse_all_nonchc.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.plot(chc_syn_loc_rot[:,0]/1000, chc_syn_loc_rot[:, 1]/1000, marker='.', linestyle='none', color=chc_color, alpha=0.2)\n",
    "ax.plot(hull_x, hull_y, color=non_color, alpha=0.5)\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([xax_min, xax_max])\n",
    "ax.set_ylim([yax_min, yax_max])\n",
    "ax.set_yticks(yticks)\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('ChC Synapses (n={})'.format(len(chc_syn_loc_rot)))\n",
    "sns.despine(offset=5, ax=ax, trim=True)\n",
    "fig.savefig(fname=plot_dir+'/synapse_all_chc.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.plot(soma_position_rot[:,0]/1000, soma_position_rot[:, 1]/1000, marker='o', linestyle='none',\n",
    "           color='k', alpha=0.8, markersize=6, markeredgecolor='w')\n",
    "ax.plot(hull_x, hull_y, color=non_color, alpha=0.5)\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([xax_min, xax_max])\n",
    "ax.set_ylim([yax_min, yax_max])\n",
    "ax.set_yticks(yticks)\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Soma')\n",
    "sns.despine(offset=5, ax=ax, trim=True)\n",
    "fig.savefig(fname=plot_dir+'/synapse_all_soma.pdf', dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,8)\n",
    "\n",
    "alldat = np.concatenate((soma_position_rot, chc_syn_loc_rot, nonchc_syn_loc_rot)) / 1000\n",
    "xax_min, yax_min, zax_min = np.min(alldat, axis=0).tolist()\n",
    "xax_max, yax_max, zax_max = np.max(alldat, axis=0).tolist()\n",
    "hull_x, hull_y = convex_hull_xy(alldat[:, [0,1]])\n",
    "\n",
    "yticks = np.arange(0,161,20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.plot(nonchc_syn_loc_rot[:,0]/1000, nonchc_syn_loc_rot[:, 1]/1000, marker='.', linestyle='none', color=non_color, alpha=0.015)\n",
    "ax.plot(chc_syn_loc_rot[:,0]/1000, chc_syn_loc_rot[:, 1]/1000, marker='.', linestyle='none', color=chc_color, alpha=0.15)\n",
    "ax.plot(hull_x, hull_y, color=non_color, alpha=0.5)\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([xax_min, xax_max])\n",
    "ax.set_ylim([yax_min, yax_max])\n",
    "ax.set_yticks(yticks)\n",
    "ax.invert_yaxis()\n",
    "sns.despine(offset=5, ax=ax, trim=True)\n",
    "fig.savefig(fname=plot_dir+'/synapse_all_chc_plus_nonchc.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = [0.05, 0.01, 0.001]\n",
    "\n",
    "bwidth = 10\n",
    "bins = np.arange(0, 150, bwidth)\n",
    "chc_depth_ct, _ = np.histogram(chc_syn_loc_rot[:,1] / 1000, bins=bins)\n",
    "non_depth_ct, _ = np.histogram(nonchc_syn_loc_rot[:,1] / 1000, bins=bins)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4), ncols=3)\n",
    "\n",
    "ax[0].grid(True, axis='x')\n",
    "ax[0].set_axisbelow(True)\n",
    "ax[0].hist(chc_syn_loc_rot[:,1] / 1000, bins=bins, orientation='horizontal', color=chc_color, edgecolor='w')\n",
    "ax[0].set_ylim(bins[0], bins[-1])\n",
    "ax[0].invert_yaxis()\n",
    "ax[0].set_ylabel('Depth ($\\mu m$)')\n",
    "ax[0].set_xlabel('# Syn ChC')\n",
    "\n",
    "ax[1].grid(True, axis='x', which='both')\n",
    "ax[1].set_axisbelow(True)\n",
    "ax[1].hist(nonchc_syn_loc_rot[:,1] / 1000, bins=bins, orientation='horizontal', color=non_color, edgecolor='w')\n",
    "ax[1].set_ylim(bins[0], bins[-1])\n",
    "ax[1].invert_yaxis()\n",
    "ax[1].set_xlabel('# Syn Non-ChC')\n",
    "\n",
    "ax[2].plot(chc_depth_ct / (non_depth_ct + chc_depth_ct), bins[0:-1]+bwidth/2, 'o:', color=chc_color, linewidth=1)\n",
    "\n",
    "pvals = []\n",
    "for chc_ct, non_ct in zip(chc_depth_ct, non_depth_ct):\n",
    "    v, p = stats.fisher_exact([[chc_ct, non_ct], [sum(chc_depth_ct), sum(non_depth_ct)]])\n",
    "    pvals.append(p)\n",
    "_, pval_corr, _, _ = multitest.multipletests(pvals, method='hs')\n",
    "n_stars = assign_stars(pval_corr, stars)\n",
    "plot_stars(chc_depth_ct / (non_depth_ct + chc_depth_ct),\n",
    "           bins[0:-1]+bwidth/2+4, n_stars, ax[2])\n",
    "\n",
    "ax[2].grid(True, axis='y')\n",
    "ax[2].set_axisbelow(True)\n",
    "\n",
    "total_fraction = np.sum(chc_depth_ct) / np.sum(chc_depth_ct + non_depth_ct)\n",
    "ax[2].plot([total_fraction, total_fraction], [bins[0], bins[-1]], 'k--')\n",
    "\n",
    "ax[2].set_xlim(-0.01, 0.08)\n",
    "ax[2].set_ylim(bins[0], bins[-1])\n",
    "ax[2].set_xticks(np.arange(0, 0.081,0.04))\n",
    "ax[2].invert_yaxis()\n",
    "ax[2].set_xlabel('Fraction Syn ChC')\n",
    "\n",
    "sns.despine(offset=5, ax=ax[0])\n",
    "sns.despine(offset=5, ax=ax[1])\n",
    "sns.despine(offset=5, ax=ax[2])\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(fname=plot_dir+'/synapse_depth_distribution.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4), ncols=2)\n",
    "ax[0].plot(chc_syn_loc_rot[:,2]/1000, chc_syn_loc_rot[:, 1]/1000, marker='.', linestyle='none', color=chc_color, alpha=0.1)\n",
    "ax[0].set_aspect(1)\n",
    "ax[0].invert_yaxis()\n",
    "ax[0].set_title('ChC Syns')\n",
    "sns.despine(offset=5, ax=ax[0])\n",
    "\n",
    "ax[1].plot(nonchc_syn_loc_rot[:,2]/1000, nonchc_syn_loc_rot[:, 1]/1000, marker='.', linestyle='none', color=non_color, alpha=0.002)\n",
    "ax[1].set_aspect(1)\n",
    "ax[1].invert_yaxis()\n",
    "ax[1].set_title('Non-ChC Syns')\n",
    "sns.despine(offset=5, ax=ax[1])\n",
    "\n",
    "fig.savefig(fname=plot_dir+'/synapse_side_views.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_pearsonr(x,y):\n",
    "    good_data_x = np.logical_and(~np.isnan(x), ~np.isinf(x))\n",
    "    good_data_y = np.logical_and(~np.isnan(y), ~np.isinf(y))\n",
    "    good_data = np.logical_and(good_data_x, good_data_y)\n",
    "    return stats.pearsonr(x[good_data], y[good_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (2, 2)\n",
    "\n",
    "arbor_ais_df['soma_y_adj'] = arbor_ais_df['soma_y_um']\n",
    "common_y = ['soma_y_adj', 'n_syn_soma', 'soma_x_um']\n",
    "if 'label' in arbor_ais_df.columns:\n",
    "    common_y += ['soma_synapses', 'soma_area', 'soma_syn_density', 'ais_radius']\n",
    "\n",
    "col_pairs = {'syn_net_chc': ['syn_net_non', 'num_cells_chc', 'syn_mean_chc'] + common_y,\n",
    "             'syn_net_non': ['syn_net_chc'] + common_y,\n",
    "             'syn_mean_chc': ['num_cells_chc'] + common_y,\n",
    "             'num_cells_chc': ['syn_mean_chc'] + common_y,\n",
    "             }\n",
    "invert_columns = ['soma_y_adj']\n",
    "tickintdict = {'soma_syn_density': False, 'syn_mean_chc': False}\n",
    "\n",
    "tick_dict = {'syn_net_chc': np.arange(0,27,5),\n",
    "             'syn_net_non': np.arange(0,27,5),\n",
    "             'soma_y_adj': np.arange(0, 121, 20),\n",
    "             'soma_x_um': np.arange(0, 251, 50),\n",
    "             'n_syn_soma': np.arange(60,161,20),\n",
    "             'soma_synapses': np.arange(40, 121, 20),\n",
    "             'soma_area': np.arange(450, 801, 100),\n",
    "             'soma_syn_density': np.arange(0.06, 0.181, 0.02),\n",
    "             'num_cells_chc': np.arange(0,10,2),\n",
    "             'syn_mean_chc': np.arange(0,8.1,2),\n",
    "             'ais_radius': np.arange(175, 376, 50)}\n",
    "\n",
    "xprecision = {'soma_syn_density': 2}\n",
    "\n",
    "needs_label = ['soma_synapses', 'soma_area', 'soma_syn_density']\n",
    "for y in col_pairs:\n",
    "    for x in col_pairs.get(y):\n",
    "        if x in needs_label or y in needs_label:\n",
    "            use_df = arbor_ais_df[row_filter]\n",
    "        else:\n",
    "            use_df = arbor_ais_df\n",
    "        fig, ax = make_scatterplot(x, y, use_df,\n",
    "                                   figsize, plot_label_lookup, tick_dict,\n",
    "                                   xtick_int=tickintdict.get(x, True),\n",
    "                                   ytick_int=tickintdict.get(y, True),\n",
    "                                   xprecision=xprecision.get(x, 1))\n",
    "        ax.set_title(f'R = {nan_pearsonr(use_df[x], use_df[y])[0]:.2f}')\n",
    "        fig.savefig(fname=plot_dir+'/scatterplots_{y}_vs_{x}.pdf'.format(x=x, y=y), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_filter = (arbor_ais_df['label']>1) & (~np.isnan(arbor_ais_df['soma_area']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_columns = [\n",
    " 'soma_synapses',\n",
    " 'soma_area',\n",
    " 'soma_syn_density',\n",
    " 'syn_net_non',\n",
    " 'ais_radius',\n",
    " 'soma_y_um']\n",
    "\n",
    "extra_corr_matrix_columns = ['syn_net_chc']+corr_matrix_columns\n",
    "ais_item_data = arbor_ais_df[row_filter][extra_corr_matrix_columns]\n",
    "\n",
    "corr_mat = np.zeros((len(extra_corr_matrix_columns), len(extra_corr_matrix_columns)))\n",
    "corr_mat_p = np.zeros((len(extra_corr_matrix_columns), len(extra_corr_matrix_columns)))\n",
    "for ii in range(len(extra_corr_matrix_columns)):\n",
    "    for jj in range(len(extra_corr_matrix_columns)):\n",
    "        r, p = nan_pearsonr(ais_item_data[extra_corr_matrix_columns[ii]], ais_item_data[extra_corr_matrix_columns[jj]])\n",
    "        corr_mat[ii,jj] = r\n",
    "        corr_mat_p[ii,jj] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest\n",
    "is_sig, corr_p, _, _ = multitest.multipletests(corr_mat_p[np.tril_indices_from(corr_mat, k=-1)])\n",
    "tri_inds = np.tril_indices_from(corr_mat, k=-1)\n",
    "put_star = []\n",
    "for ii, jj, sig in zip(*tri_inds, is_sig):\n",
    "    if sig:\n",
    "        put_star.append([ii, jj])\n",
    "put_star = np.array(put_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_plot = False \n",
    "\n",
    "mask = np.zeros_like(corr_mat, dtype=np.bool)\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "\n",
    "cmap = sns.color_palette('RdBu', n_colors=31)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(corr_mat, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "ax.plot(put_star[:,0]+0.5, put_star[:,1]+0.5, 'k*')\n",
    "ax.set_yticks(np.arange(0.5, len(extra_corr_matrix_columns)-1+0.5))\n",
    "_=ax.set_yticklabels([plot_label_lookup[x] for x in extra_corr_matrix_columns[:-1]], rotation=0)\n",
    "\n",
    "ax.set_xticks(np.arange(1.5, len(extra_corr_matrix_columns)+0.5))\n",
    "_=ax.set_xticklabels([plot_label_lookup[x] for x in extra_corr_matrix_columns[1:]], rotation=45)\n",
    "ax.xaxis.tick_top()\n",
    "if do_plot is True:\n",
    "    fig.savefig(f'{plot_dir}/variable_correlation_structure.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import *\n",
    "\n",
    "ais_item_data = arbor_ais_df[row_filter][corr_matrix_columns]\n",
    "Xdat = ais_item_data.values\n",
    "Xz = stats.zscore(Xdat, axis=0)\n",
    "\n",
    "# pca = SparsePCA(n_components=3, random_state=100 )\n",
    "pca = FastICA(n_components=3, random_state=1004 )\n",
    "\n",
    "Xz_pca = pca.fit_transform(Xz)\n",
    "\n",
    "for ii in range(pca.n_components):\n",
    "    if pca.components_[ii,np.argmax(np.abs(pca.components_[ii,:]))] < 0:   # If the dominant component is negative\n",
    "        pca.components_[ii, :] = -1 * pca.components_[ii, :]\n",
    "        Xz_pca[:,ii] = -1 * Xz_pca[:,ii]\n",
    "\n",
    "do_plot = True \n",
    "for ii in range(pca.n_components):\n",
    "    fig, ax = plt.subplots(figsize=(1,2))\n",
    "    ax.barh(np.arange(pca.components_.shape[1]), pca.components_[ii,:], height=0.5, color='k')\n",
    "    ax.vlines(0, -1, 6, linewidth=1)\n",
    "    ax.set_ylim((-0.5, 5.5))\n",
    "    ax.set_yticks(np.arange(pca.components_.shape[1]))\n",
    "    ax.set_yticklabels([plot_label_lookup[x] for x in corr_matrix_columns])\n",
    "    ax.invert_yaxis()\n",
    "    maxval=np.max(np.abs(pca.components_[ii,:]))\n",
    "    ax.set_xlim((-maxval, maxval))\n",
    "    ax.set_xticks((-maxval, 0, maxval))\n",
    "    ax.set_xticklabels((f'{-maxval:0.2f}', '0', f'{maxval:0.2f}'))\n",
    "    sns.despine(ax=ax, offset=5, trim=True)\n",
    "    ax.set_title(f'PC {ii}')\n",
    "    if do_plot:\n",
    "        fig.savefig(f'{plot_dir}/factor_component_{ii}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "sns.scatterplot(x=Xz_pca[:, 0], y=Xz_pca[:,1], hue=Xz_pca[:,2], s=70,  palette='viridis', legend='brief')\n",
    "ax.set_xlabel('\"Non-ChC Input\"', fontdict={'size':14})\n",
    "ax.set_ylabel('\"Soma Size\"', fontdict={'size':14})\n",
    "ax.legend(bbox_to_anchor=(1.1, 1))\n",
    "sns.despine(ax=ax, offset=5)\n",
    "\n",
    "fig.savefig(f'{plot_dir}/post_ica_scatter.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df_use = arbor_ais_df[row_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(pca.n_components):\n",
    "    arbor_ais_df_use[f'pca_{ii}'] = Xz_pca[:,ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_lookup = {'syn_net_chc': '# ChC Syn.',\n",
    "                     'syn_net_non': '# Non-ChC Syn.',\n",
    "                     'size_net_chc': 'Net ChC Syn. Size',\n",
    "                     'soma_y_adj': 'Soma Depth ($\\mu m$)',\n",
    "                     'soma_y_um': 'Soma Depth ($\\mu m$)',\n",
    "                     'soma_x_um': 'Soma Mediolateral Pos. ($\\mu m$)',\n",
    "                     'n_syn_soma': '# Syn Soma',\n",
    "                     'soma_synapses': '# Syn Soma',\n",
    "                     'soma_area': 'Soma Area ($\\mu m^2$)',\n",
    "                     'soma_syn_density': '# Syn Soma/($\\mu m^2$)',\n",
    "                     'num_cells_chc': '# ChC Connections',\n",
    "                     'syn_mean_chc': '# Syn/Connection',\n",
    "                     'conn_frac': 'Connectivity Fraction',\n",
    "                     'num_potential': '# Potential ChC',\n",
    "                     'size_mean_chc': 'Mean ChC Syn Size',\n",
    "                     'pca_2': 'Soma Size Comp.',\n",
    "                     'pca_0': 'Soma Depth Comp.',\n",
    "                     'pca_1': 'Soma Inhibition Comp.',\n",
    "                     'pca_3': 'PC 3',\n",
    "                     'pca_4': 'PC 4',\n",
    "                     'ais_radius': 'AIS Radius',\n",
    "                     'syn_max_chc': 'Max Syn ChC',\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_filter_true = arbor_ais_df_use['post_pt_root_id']>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_save= True \n",
    "ls_prefix = {True: 'rls', False: 'ols'}\n",
    "for use_robust in [True, False]:\n",
    "    ### Same for good soma cutout\n",
    "    base_variables = [f'pca_{ii}' for ii in range(pca.n_components)]\n",
    "\n",
    "    y_col = 'syn_net_chc'\n",
    "    columns_chc = base_variables\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, 'syn_net_chc', columns_chc[::-1], chc_color, robust=use_robust, plot_label_lookup=plot_label_lookup, xticks=np.arange(-0.75,.76,0.25))\n",
    "    if do_save:\n",
    "        res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.csv'.format(y_col), index=False)\n",
    "        fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "        residual_scatterplots(y_col, columns_chc, row_filter_true, arbor_ais_df_use, 'exact', plot_dir, plot_label_lookup=plot_label_lookup, robust=use_robust)\n",
    "    \n",
    "    y_col = 'size_net_chc'\n",
    "    columns_chc = base_variables\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_chc[::-1], chc_color, robust=use_robust, plot_label_lookup=plot_label_lookup, xticks=np.arange(-0.75,.76,0.25))\n",
    "    if do_save:\n",
    "        res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.csv'.format(y_col), index=False)\n",
    "        fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "        residual_scatterplots(y_col, columns_chc, row_filter_true, arbor_ais_df_use, 'exact', plot_dir, plot_label_lookup=plot_label_lookup, robust=use_robust)\n",
    "\n",
    "    y_col = 'syn_mean_chc'\n",
    "    columns_mean = base_variables\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_mean[::-1], syn_per_conn_color, robust=use_robust, plot_label_lookup=plot_label_lookup, xticks=np.arange(-0.75,.76,0.25))\n",
    "    if do_save:\n",
    "        res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.csv'.format(y_col), index=False)\n",
    "        fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "        residual_scatterplots(y_col, columns_chc, row_filter_true, arbor_ais_df_use, 'exact', plot_dir, plot_label_lookup=plot_label_lookup, robust=use_robust)\n",
    "\n",
    "    y_col = 'num_cells_chc'\n",
    "    columns_num = base_variables\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_num[::-1], num_conn_color, robust=use_robust, plot_label_lookup=plot_label_lookup, xticks=np.arange(-0.75,.76,0.25))\n",
    "    if do_save:\n",
    "        res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.csv'.format(y_col), index=False)\n",
    "        fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "        residual_scatterplots(y_col, columns_chc, row_filter_true, arbor_ais_df_use, 'exact', plot_dir, plot_label_lookup=plot_label_lookup, robust=use_robust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ycol in ['syn_net_chc', 'syn_mean_chc', 'num_cells_chc']:\n",
    "    for xcol in base_variables:\n",
    "        for use_robust in [True, False]:\n",
    "            fig, ax = plt.subplots(figsize=(3,3))\n",
    "            sns.regplot(x=xcol, y=ycol, data=arbor_ais_df_use, ax=ax, marker='o', color='k', scatter_kws={'s':8, 'color':(0.3, 0.3, 0.3)}, robust=use_robust, n_boot=100)\n",
    "            sns.despine(ax=ax, offset=5)\n",
    "            ax.set_xlabel(plot_label_lookup[xcol])\n",
    "            ax.set_ylabel(plot_label_lookup[ycol])\n",
    "            r=nan_pearsonr(arbor_ais_df_use[xcol], arbor_ais_df_use[ycol])[0]\n",
    "            ax.set_title(f'R$^2$={r*r:.2f}')\n",
    "            fig.savefig(f'{plot_dir}/linear_plot_robust_{use_robust}_{ycol}_vs_{xcol}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_prefix = {True: 'rls', False: 'ols'}\n",
    "# for use_robust in [True, False]:\n",
    "#     ### Same for good soma cutout\n",
    "#     base_variables = corr_matrix_columns\n",
    "\n",
    "#     y_col = 'syn_net_chc'\n",
    "#     columns_chc = ['syn_net_non'] + base_variables\n",
    "#     fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, 'syn_net_chc', columns_chc[::-1], chc_color, robust=use_robust, plot_label_lookup=plot_label_lookup,  xticks=np.arange(-0.75,.76,0.25))\n",
    "#     res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.csv'.format(y_col), index=False)\n",
    "#     fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "#     residual_scatterplots(y_col, columns_chc, row_filter, arbor_ais_df, 'exact', plot_dir,  plot_label_lookup=plot_label_lookup,robust=robust)\n",
    "\n",
    "#     y_col = 'size_net_chc'\n",
    "#     columns_chc = ['syn_net_non'] + base_variables\n",
    "#     fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, 'size_net_chc', columns_chc[::-1], chc_color, robust=use_robust, plot_label_lookup=plot_label_lookup,  xticks=np.arange(-0.75,.76,0.25))\n",
    "#     res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.csv'.format(y_col), index=False)\n",
    "#     fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "#     residual_scatterplots(y_col, columns_chc, row_filter, arbor_ais_df, 'exact', plot_dir,  plot_label_lookup=plot_label_lookup,robust=robust)\n",
    "    \n",
    "#     y_col = 'syn_net_non'\n",
    "#     columns_non = ['syn_net_chc'] + base_variables\n",
    "#     fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_non[::-1], non_color, robust=use_robust, plot_label_lookup=plot_label_lookup, xticks=np.arange(-0.75,.76,0.25))\n",
    "#     res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.csv'.format(y_col), index=False)\n",
    "#     fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "#     residual_scatterplots(y_col, columns_non, row_filter, arbor_ais_df, 'exact', plot_dir,  plot_label_lookup=plot_label_lookup,robust=robust)\n",
    "\n",
    "#     y_col = 'syn_mean_chc'\n",
    "#     columns_mean = ['syn_net_non'] + base_variables\n",
    "#     fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_mean[::-1], syn_per_conn_color, robust=use_robust, plot_label_lookup=plot_label_lookup, xticks=np.arange(-0.75,.76,0.25))\n",
    "#     res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.csv'.format(y_col), index=False)\n",
    "#     fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "#     residual_scatterplots(y_col, columns_mean, row_filter, arbor_ais_df, 'exact', plot_dir,  plot_label_lookup=plot_label_lookup,robust=robust)\n",
    "\n",
    "#     y_col = 'num_cells_chc'\n",
    "#     columns_num = ['syn_net_non'] + base_variables\n",
    "#     fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_num[::-1], num_conn_color, robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "#     res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.csv'.format(y_col), index=False)\n",
    "#     fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_exact_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "#     residual_scatterplots(y_col, columns_num, row_filter, arbor_ais_df, 'exact', plot_dir,  plot_label_lookup=plot_label_lookup,robust=robust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Same for soma synapse density\n",
    "for use_robust in [True, False]:\n",
    "\n",
    "    columns_chc = ['soma_syn_density', 'syn_net_non', 'soma_y_um', 'soma_x_um', 'ais_radius']\n",
    "    y_col = 'syn_net_chc'\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, 'syn_net_chc', columns_chc[::-1], chc_color, robust=use_robust,  xticks=np.arange(-0.75,.76,0.25))\n",
    "    res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.csv'.format(y_col), index=False)\n",
    "    fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "    residual_scatterplots(y_col, columns_chc, row_filter, arbor_ais_df, 'density', plot_dir, robust=robust)\n",
    "\n",
    "    columns_non = ['soma_syn_density', 'syn_net_chc', 'soma_y_um', 'soma_x_um', 'ais_radius']\n",
    "    y_col = 'syn_net_non'\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_non[::-1], non_color, robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "    res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.csv'.format(y_col), index=False)\n",
    "    fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "    residual_scatterplots(y_col, columns_non, row_filter, arbor_ais_df, 'density', plot_dir, robust=robust)\n",
    "\n",
    "    y_col = 'syn_mean_chc'\n",
    "    columns_mean = ['soma_syn_density', 'syn_net_non', 'soma_y_um', 'soma_x_um', 'ais_radius']\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_mean[::-1], syn_per_conn_color, robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "    res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.csv'.format(y_col), index=False)\n",
    "    fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "    residual_scatterplots(y_col, columns_mean, row_filter, arbor_ais_df, 'density', plot_dir, robust=robust)\n",
    "\n",
    "    y_col = 'num_cells_chc'\n",
    "    columns_num = ['soma_syn_density', 'syn_net_non', 'soma_y_um', 'soma_x_um', 'ais_radius']\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_use, row_filter_true, y_col, columns_num[::-1], num_conn_color, robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "    res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.csv'.format(y_col), index=False)\n",
    "    fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_soma_density_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "    residual_scatterplots(y_col, columns_num, row_filter, arbor_ais_df, 'density', plot_dir, robust=robust)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Spatial considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshparty import skeletonize, mesh_filters\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_ball_radius = 10000\n",
    "axon_component_thresh = 0.00018 # synapse vertices per component vertex\n",
    "\n",
    "chc_soma_df = soma_df.query(f'pt_root_id in {chc_ids.tolist()}')\n",
    "chc_soma_ids = chc_soma_df['pt_root_id'].values\n",
    "chc_soma_pts = np.vstack(chc_soma_df['pt_position'].values) * voxel_resolution\n",
    "\n",
    "for chc_oid in chc_soma_ids:\n",
    "    if not os.path.exists(f'{mesh_dir}/{chc_oid}_axon.h5'):\n",
    "        print(f'Extracting axon for {chc_oid}...')\n",
    "        chc_soma_mesh = mm.mesh(seg_id = chc_oid)\n",
    "        chc_soma_mesh.add_link_edges(dataset_name='pinky100', seg_id=chc_oid)\n",
    "        chc_soma_mesh = chc_soma_mesh.apply_mask(mesh_filters.filter_components_by_size(chc_soma_mesh, min_size=1000))\n",
    "\n",
    "        out_syn_df = dl.query_synapses(synapse_table, pre_ids=[chc_oid])\n",
    "        out_syn_pts = np.vstack(out_syn_df['ctr_pt_position'].values) * voxel_resolution\n",
    "\n",
    "        ds, minds = chc_soma_mesh.kdtree.query(out_syn_pts, distance_upper_bound=250)\n",
    "        minds = chc_soma_mesh.map_indices_to_unmasked(minds[~np.isinf(ds)])\n",
    "\n",
    "        soma_ball = mesh_filters.filter_spatial_distance_from_points(chc_soma_mesh, chc_soma_pts, soma_ball_radius)\n",
    "        chc_soma_mesh_nonsoma = chc_soma_mesh.apply_mask(~soma_ball)\n",
    "        filtered_minds = chc_soma_mesh_nonsoma.filter_unmasked_indices(minds)\n",
    "\n",
    "        _, comp_inds = sparse.csgraph.connected_components(chc_soma_mesh_nonsoma.csgraph)\n",
    "\n",
    "        all_comp_ind, comp_vert_counts = np.unique(comp_inds, return_counts=True)\n",
    "        pre_syn_comp_ind, pre_syn_counts = np.unique(comp_inds[filtered_minds], return_counts=True)\n",
    "\n",
    "        pre_syn_counts_all = np.zeros(all_comp_ind.shape)\n",
    "        pre_syn_counts_all[pre_syn_comp_ind] = pre_syn_counts\n",
    "        axon_components = all_comp_ind[pre_syn_counts_all/comp_vert_counts > axon_component_thresh]\n",
    "\n",
    "        axon_minds = np.isin(comp_inds, axon_components)\n",
    "        chc_axon_mesh = chc_soma_mesh_nonsoma.apply_mask(axon_minds)\n",
    "        chc_axon_mesh.write_to_file(f'{mesh_dir}/{chc_oid}_axon.h5')\n",
    "    else:\n",
    "        print(f'Already extracted axon for {chc_oid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = trimesh_io.MeshMeta(disk_cache_path=mesh_dir,\n",
    "                         cache_size=0, cv_path=mesh_cv_path, voxel_scaling=voxel_scaling)\n",
    "\n",
    "ais_meshes = {} \n",
    "for oid in complete_ais_ids:\n",
    "    ais_file = ais_mesh_dir + '/{}_ais.h5'.format(oid)\n",
    "    if os.path.exists(ais_file):\n",
    "        ais_mesh = mm.mesh(filename=ais_file, voxel_scaling=voxel_scaling)\n",
    "        ais_meshes[oid] = ais_mesh\n",
    "    else:\n",
    "        ais_meshes[oid] = None\n",
    "        print('{} AIS not found!'.format(oid))\n",
    "\n",
    "chc_meshes = {}\n",
    "for oid in chc_ids:\n",
    "    if oid not in chc_soma_ids:\n",
    "        chc_mesh = mm.mesh(seg_id=oid, voxel_scaling=voxel_scaling)\n",
    "    else:\n",
    "        chc_mesh = mm.mesh(filename=mesh_dir + '/{}_axon.h5'.format(oid), voxel_scaling=voxel_scaling)\n",
    "    chc_meshes[oid] = chc_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the multi-utilities to get potential synapses from meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from meshparty import skeletonize, skeleton_io\n",
    "\n",
    "data_dir = base_dir + '/data'\n",
    "\n",
    "from multiwrapper import multiprocessing_utils as mu\n",
    "def _multi_count_neighbors(args):\n",
    "    ais_kdt, chc_kdt, d_max = args\n",
    "    return ais_kdt.count_neighbors(chc_kdt, d_max)\n",
    "\n",
    "ais_sks = {} \n",
    "for oid in complete_ais_ids:\n",
    "    ais_sk_filename = skel_dir + '/sk_ais_{}.h5'.format(oid)\n",
    "    ais_sk = skeleton_io.read_skeleton_h5(ais_sk_filename)\n",
    "    ais_sk.voxel_scaling = None\n",
    "    ais_sks[oid] = ais_sk\n",
    "    \n",
    "# chc_sks = []\n",
    "# for chc_oid in chc_meshes:\n",
    "#     chc_sk_filename = skel_dir + '/sk_chc_axon_{}.h5'.format(chc_oid)\n",
    "#     if os.path.exists(chc_sk_filename):\n",
    "#         chc_sks.append(skeleton_io.read_skeleton_h5(chc_sk_filename))\n",
    "#     else:\n",
    "#         chc_sk = skeletonize.skeletonize_mesh(chc_meshes[chc_oid], invalidation_d=4000)\n",
    "#         chc_sks.append(chc_sk)\n",
    "#         skeleton_io.write_skeleton_h5(chc_sk, chc_sk_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vec = [5000, 7500, 10000, 15000]\n",
    "is_potential_ds = {}\n",
    "for d_max in d_vec:\n",
    "    multi_args = []\n",
    "    for ais_oid, chc_mesh in product(complete_ais_ids, chc_meshes.values()):\n",
    "        ais_sk = ais_sks[ais_oid]\n",
    "        fair_inds = ais_sk.distance_to_root < min_ais_len\n",
    "        ais_sk_fair_verts = ais_sk.vertices[fair_inds]\n",
    "        ais_fair_kdt = spatial.cKDTree(ais_sk_fair_verts)\n",
    "        \n",
    "        multi_args.append([ais_fair_kdt, chc_mesh.kdtree, d_max])    \n",
    "\n",
    "    n_neib_list = mu.multiprocess_func(_multi_count_neighbors, multi_args, verbose=True)\n",
    "\n",
    "    is_potential = defaultdict(dict)\n",
    "    n_neib_list_copy = n_neib_list.copy()\n",
    "    for ais_ind, chc_oid in product(range(len(ais_meshes)), chc_meshes.keys()):\n",
    "        is_potential[ais_ind][chc_oid] = n_neib_list_copy.pop(0)>0\n",
    "    is_potential_ds[d_max] = is_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_dict = {'syn_net_chc': np.arange(0,27,5),\n",
    "             'syn_net_non': np.arange(0,27,5),\n",
    "             'soma_y_adj': np.arange(0, 121, 20),\n",
    "             'soma_x_um': np.arange(0, 251, 50),\n",
    "             'n_syn_soma': np.arange(60,161,20),\n",
    "             'soma_synapses': np.arange(40, 121, 20),\n",
    "             'soma_area': np.arange(500, 901, 100),\n",
    "             'soma_syn_density': np.arange(0.05, 0.15, 0.02),\n",
    "             'num_cells_chc': np.arange(0,10,2.5),\n",
    "             'syn_mean_chc': np.arange(0,8,2),\n",
    "             'conn_frac': np.arange(0,1.01,0.2),\n",
    "             'num_potential': np.arange(0, 21, 5),\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_cutoff = 0.1\n",
    "is_potential = is_potential_ds[10000]\n",
    "\n",
    "num_pot_df = pd.DataFrame({'pyc_root_id': complete_ais_ids, 'num_potential':[sum(is_potential[ii].values()) for ii in range(len(complete_ais_ids))]})\n",
    "arbor_ais_df_pot = arbor_ais_df_use.merge(num_pot_df, left_on='post_pt_root_id', right_on='pyc_root_id', how='left').drop(columns=['pyc_root_id'])\n",
    "arbor_ais_df_pot['conn_frac'] = arbor_ais_df_pot['num_cells_chc'] / arbor_ais_df_pot['num_potential']\n",
    "mask_frac_df = pd.read_hdf(data_dir + '/mask_fraction_data_v{}.hdf'.format(data_version))\n",
    "ais_oid_within_limits = mask_frac_df[mask_frac_df['d_{}'.format(d_max)] < fraction_cutoff]['root_id']\n",
    "within_unmasked = np.isin(arbor_ais_df_pot['post_pt_root_id'], ais_oid_within_limits)\n",
    "arbor_ais_df_pot = arbor_ais_df_pot[within_unmasked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_df = arbor_ais_df_pot \n",
    "\n",
    "x = 'num_potential'\n",
    "y = 'syn_net_chc'\n",
    "fig, ax = make_scatterplot(x, y, arbor_ais_df_pot,\n",
    "                           figsize, plot_label_lookup, tick_dict,\n",
    "                           xtick_int=tickintdict.get(x, True),\n",
    "                           ytick_int=tickintdict.get(y, True),\n",
    "                           xprecision=xprecision.get(x, 1))\n",
    "ax.set_title(f'R = {nan_pearsonr(use_df[x], use_df[y])[0]:.2f}')\n",
    "fig.savefig(fname=f'{plot_dir}/scatterplots_{y}_vs_{x}.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "x = 'conn_frac'\n",
    "y = 'syn_net_chc'\n",
    "fig, ax = make_scatterplot(x, y, arbor_ais_df_pot,\n",
    "                           figsize, plot_label_lookup, tick_dict,\n",
    "                           xtick_int=tickintdict.get(x, True),\n",
    "                           ytick_int=tickintdict.get(y, True),\n",
    "                           xprecision=xprecision.get(x, 1))\n",
    "ax.set_title(f'R = {nan_pearsonr(use_df[x], use_df[y])[0]:.2f}')\n",
    "fig.savefig(fname=f'{plot_dir}/scatterplots_{y}_vs_{x}.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "x = 'conn_frac'\n",
    "y = 'num_potential'\n",
    "fig, ax = make_scatterplot(x, y, arbor_ais_df_pot,\n",
    "                           figsize, plot_label_lookup, tick_dict,\n",
    "                           xtick_int=tickintdict.get(x, True),\n",
    "                           ytick_int=tickintdict.get(y, True),\n",
    "                           xprecision=xprecision.get(x, 1))\n",
    "ax.set_title(f'R = {nan_pearsonr(use_df[x], use_df[y])[0]:.2f}')\n",
    "fig.savefig(fname=f'{plot_dir}/scatterplots_{y}_vs_{x}.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_cutoff = 0.1\n",
    "figsize = (2, 2)\n",
    "\n",
    "n_pot_dist = {}\n",
    "base_variables = ['pca_0', 'pca_1', 'pca_2']\n",
    "\n",
    "for d_max in d_vec:\n",
    "\n",
    "    is_potential = is_potential_ds[d_max]\n",
    "\n",
    "    num_pot_df = pd.DataFrame({'pyc_root_id': complete_ais_ids, 'num_potential':[sum(is_potential[ii].values()) for ii in range(len(complete_ais_ids))]})\n",
    "    arbor_ais_df_pot = arbor_ais_df_use.merge(num_pot_df, left_on='post_pt_root_id', right_on='pyc_root_id', how='left').drop(columns=['pyc_root_id'])\n",
    "    arbor_ais_df_pot['conn_frac'] = arbor_ais_df_pot['num_cells_chc'] / arbor_ais_df_pot['num_potential']\n",
    "\n",
    "    mask_frac_df = pd.read_hdf(data_dir + '/mask_fraction_data_v{}.hdf'.format(data_version))\n",
    "    ais_oid_within_limits = mask_frac_df[mask_frac_df['d_{}'.format(d_max)] < fraction_cutoff]['root_id']\n",
    "    within_unmasked = np.isin(arbor_ais_df_pot['post_pt_root_id'], ais_oid_within_limits)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.hist(arbor_ais_df_pot[within_unmasked]['conn_frac'], bins=np.arange(0,1.01,0.1), edgecolor='w', color='k')\n",
    "    ax.grid(True, axis='y')\n",
    "    ax.set_axisbelow(True)\n",
    "    sns.despine(offset=2, trim=False, ax=ax)\n",
    "    ax.set_xlabel('Connectivity fraction')\n",
    "    ax.set_yticks(np.arange(0,31,5))\n",
    "    ax.set_ylabel('# AISes')\n",
    "\n",
    "    fig.savefig(fname=plot_dir+'/connectivity_fraction_histogram_dmax_{}.pdf'.format(d_max), bbox_inches=\"tight\")\n",
    "\n",
    "    conn_fract_described_df = arbor_ais_df_pot[within_unmasked]['conn_frac'].describe(percentiles=[0.5])\n",
    "    conn_fract_described_df.to_csv(plot_dir + '/connectivity_fraction_summary_v{}_dmax_{}.csv'.format(data_version, d_max))\n",
    "\n",
    "    \n",
    "    n_pot_dist[d_max] = arbor_ais_df_pot[['post_pt_root_id', 'num_potential', 'num_cells_chc', 'size_net_chc']].rename(columns={'num_potential':'num_potential_{}'.format(d_max),\n",
    "                                                                                             'num_cells_chc': 'num_cells_chc_{}'.format(d_max),\n",
    "                                                                                             'size_net_chc': 'size_net_chc_{}'.format(d_max),\n",
    "                                                                                             'post_pt_root_id': 'post_pt_root_id_{}'.format(d_max)})\n",
    "    n_pot_dist[d_max]['within_data_{}'.format(d_max)] = within_unmasked\n",
    "    \n",
    "    common_y = ['soma_y_adj', 'n_syn_soma', 'syn_net_non', 'soma_x_um']\n",
    "    if 'label' in arbor_ais_df.columns:\n",
    "        common_y += ['n_syn_soma', 'soma_syn_density']\n",
    "\n",
    "    new_col_pairs = {}\n",
    "    new_col_pairs['conn_frac'] = common_y\n",
    "    new_col_pairs['num_potential'] = common_y\n",
    "\n",
    "    tickintdict['conn_frac'] = False\n",
    "\n",
    "#     for x in new_col_pairs:\n",
    "#         for y in new_col_pairs.get(x):\n",
    "#             fig, ax = make_scatterplot(y, x, arbor_ais_df_pot[within_unmasked],\n",
    "#                                        figsize, plot_label_lookup, tick_dict,\n",
    "#                                        xtick_int=tickintdict.get(y, True),\n",
    "#                                        ytick_int=tickintdict.get(x, True),\n",
    "#                                        xprecision=xprecision.get(y, 1))\n",
    "#             fig.savefig(fname=plot_dir+'/scatterplots_{x}_vs_{y}_dmax_{d}.pdf'.format(x=x, y=y, d=d_max), bbox_inches=\"tight\")\n",
    "    \n",
    "    #### OLS plots\n",
    "    \n",
    "    for use_robust in [True, False]:\n",
    "        y_col = 'conn_frac'\n",
    "        columns_frac = base_variables\n",
    "        fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, within_unmasked, y_col, columns_frac[::-1], conn_frac_color,\n",
    "                                              robust=use_robust, xticks=np.arange(-0.75,.76,0.25), plot_label_lookup=plot_label_lookup)\n",
    "        res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}_d{d_max}.csv'.format(y_col), index=False)\n",
    "        fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}_d{d_max}.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "        y_col = 'num_potential'\n",
    "        columns_pot = base_variables\n",
    "        fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, within_unmasked, y_col, columns_pot[::-1], num_pot_color,\n",
    "                                              robust=use_robust, xticks=np.arange(-0.75,.76,0.25), plot_label_lookup=plot_label_lookup)\n",
    "        res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}_d{d_max}.csv'.format(y_col), index=False)\n",
    "        fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}_d{d_max}.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "        for ycol in ['conn_frac', 'num_potential']:\n",
    "            for xcol in base_variables:\n",
    "                for use_robust in [True, False]:\n",
    "                    fig, ax = plt.subplots(figsize=(3,3))\n",
    "                    sns.regplot(x=xcol, y=ycol, data=arbor_ais_df_pot, ax=ax, marker='o', color='k', scatter_kws={'s':8, 'color':(0.3, 0.3, 0.3)}, robust=use_robust, n_boot=300)\n",
    "                    sns.despine(ax=ax, offset=5)\n",
    "                    ax.set_xlabel(plot_label_lookup[xcol])\n",
    "                    ax.set_ylabel(plot_label_lookup[ycol])\n",
    "                    r=nan_pearsonr(arbor_ais_df_pot[xcol], arbor_ais_df_pot[ycol])[0]\n",
    "                    ax.set_title(f'R$^2$={r*r:.2f}')\n",
    "                    fig.savefig(f'{plot_dir}/linear_plot_robust_{use_robust}_{ycol}_vs_{xcol}.pdf')\n",
    "                    residual_scatterplots(ycol, base_variables, arbor_ais_df_pot['post_pt_root_id']>0, arbor_ais_df_pot, 'exact', plot_dir, plot_label_lookup=plot_label_lookup, robust=use_robust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = n_pot_dist[d_vec[0]]\n",
    "for dval in d_vec[1:]:\n",
    "    out_df = out_df.merge(n_pot_dist[dval],left_index=True, right_index=True)\n",
    "\n",
    "out_df = out_df.rename(columns = {'num_cells_chc_10000':'num_conn_chc', 'size_net_chc_10000':'size_net_chc', 'post_pt_root_id_10000':'pt_root_id'})\n",
    "drop_columns = ['num_cells_chc_7500', 'size_net_chc_7500', 'post_pt_root_id_7500',\n",
    "                'num_cells_chc_5000', 'size_net_chc_5000', 'post_pt_root_id_5000',\n",
    "                'num_cells_chc_15000', 'size_net_chc_15000', 'post_pt_root_id_15000',]\n",
    "out_df = out_df.drop(columns=drop_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(data_dir + '/out/potential_synapse_counts_truncated_v{}.csv'.format(data_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Input density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dend_df = pd.read_hdf(base_dir+'/data/in/spatial_arbor_synapses_v{}.h5'.format(data_version), 'arbor_synapse_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='dend_syn', y='dend_area', data=dend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dend_df['dend_syn_density'] = dend_df['dend_syn'] / dend_df['dend_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_density_df = arbor_ais_df_pot.merge(dend_df[['pt_root_id', 'dend_syn_density']], left_on='post_pt_root_id', right_on='pt_root_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_lookup['dend_syn_density'] = 'Dend Syn. Density ($1/\\mu m^2$)'\n",
    "tick_dict['dend_syn_density'] = np.arange(0.19, 0.35, 0.03)\n",
    "\n",
    "fig, ax = make_scatterplot('dend_syn_density', 'syn_net_chc', arbor_ais_density_df,\n",
    "                           (2,2), plot_label_lookup, tick_dict,\n",
    "                           xtick_int=False,\n",
    "                           ytick_int=tickintdict.get(y, True),\n",
    "                           xprecision=2)\n",
    "fig.savefig(plot_dir + '/scatterplots_{}_v_{}.pdf'.format('dend_syn_density', 'syn_net_chc'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(arbor_ais_density_df['dend_syn_density'], arbor_ais_density_df['syn_net_chc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_lookup['dend_syn_density'] = 'Dend Syn. Density ($1/\\mu m^2$)'\n",
    "tick_dict['dend_syn_density'] = np.arange(0.22, 0.32, 0.03)\n",
    "\n",
    "fig, ax = make_scatterplot('dend_syn_density', 'syn_net_non', arbor_ais_density_df,\n",
    "                           (2,2), plot_label_lookup, tick_dict,\n",
    "                           xtick_int=False,\n",
    "                           ytick_int=tickintdict.get(y, True),\n",
    "                           xprecision=2)\n",
    "fig.savefig(plot_dir + '/scatterplots_{}_v_{}.pdf'.format('dend_syn_density', 'syn_net_non'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_density_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbor_ais_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_lookup['ais_radius'] = 'AIS rad ($\\mu m$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_cutoff = 0.1\n",
    "figsize = (2, 2)\n",
    "use_robust = False\n",
    "\n",
    "n_pot_dist = {}\n",
    "\n",
    "for d_max in d_vec:\n",
    "\n",
    "    is_potential = is_potential_ds[d_max]\n",
    "\n",
    "    num_pot_df = pd.DataFrame({'pyc_root_id': complete_ais_ids, 'num_potential':[sum(is_potential[ii].values()) for ii in range(len(complete_ais_ids))]})\n",
    "    arbor_ais_df_pot = arbor_ais_df_r.merge(num_pot_df, left_on='post_pt_root_id', right_on='pyc_root_id', how='left').drop(columns=['pyc_root_id'])\n",
    "    arbor_ais_df_pot['conn_frac'] = arbor_ais_df_pot['num_cells_chc'] / arbor_ais_df_pot['num_potential']\n",
    "\n",
    "    mask_frac_df = pd.read_hdf(data_dir + '/mask_fraction_data_v{}.hdf'.format(data_version))\n",
    "    ais_oid_within_limits = mask_frac_df[mask_frac_df['d_{}'.format(d_max)] < fraction_cutoff]['root_id']\n",
    "    within_unmasked = np.isin(arbor_ais_df_pot['post_pt_root_id'], ais_oid_within_limits)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.hist(arbor_ais_df_pot[within_unmasked]['conn_frac'], bins=np.arange(0,1.01,0.1), edgecolor='w', color='k')\n",
    "    ax.grid(True, axis='y')\n",
    "    ax.set_axisbelow(True)\n",
    "    sns.despine(offset=2, trim=False, ax=ax)\n",
    "    ax.set_xlabel('Connectivity fraction')\n",
    "    ax.set_yticks(np.arange(0,31,5))\n",
    "    ax.set_ylabel('# AISes')\n",
    "\n",
    "    arbor_ais_df_pot['conn_frac'].describe()\n",
    "    fig.savefig(fname=plot_dir+'/connectivity_fraction_histogram_dmax_{}.pdf'.format(d_max), bbox_inches=\"tight\")\n",
    "\n",
    "    conn_fract_described_df = arbor_ais_df_pot[within_unmasked]['conn_frac'].describe(percentiles=[0.5])\n",
    "    conn_fract_described_df.to_csv(plot_dir + '/connectivity_fraction_summary_v{}_dmax_{}.csv'.format(data_version, d_max))\n",
    "\n",
    "    \n",
    "    n_pot_dist[d_max] = arbor_ais_df_pot[['post_pt_root_id', 'num_potential', 'num_cells_chc', 'size_net_chc']].rename(columns={'num_potential':'num_potential_{}'.format(d_max),\n",
    "                                                                                             'num_cells_chc': 'num_cells_chc_{}'.format(d_max),\n",
    "                                                                                             'size_net_chc': 'size_net_chc_{}'.format(d_max),\n",
    "                                                                                             'post_pt_root_id': 'post_pt_root_id_{}'.format(d_max)})\n",
    "    n_pot_dist[d_max]['within_data_{}'.format(d_max)] = within_unmasked\n",
    "    \n",
    "    common_y = ['soma_y_adj', 'n_syn_soma', 'syn_net_non', 'soma_x_um']\n",
    "    if 'label' in arbor_ais_df.columns:\n",
    "        common_y += ['soma_synapses', 'soma_syn_density']\n",
    "\n",
    "    new_col_pairs = {}\n",
    "    new_col_pairs['conn_frac'] = common_y\n",
    "    new_col_pairs['num_potential'] = common_y\n",
    "\n",
    "    tickintdict['conn_frac'] = False\n",
    "\n",
    "    for x in new_col_pairs:\n",
    "        for y in new_col_pairs.get(x):\n",
    "            fig, ax = make_scatterplot(y, x, arbor_ais_df_pot[within_unmasked],\n",
    "                                       figsize, plot_label_lookup, tick_dict,\n",
    "                                       xtick_int=tickintdict.get(y, True),\n",
    "                                       ytick_int=tickintdict.get(x, True),\n",
    "                                       xprecision=xprecision.get(y, 1))\n",
    "            fig.savefig(fname=plot_dir+'/scatterplots_{x}_vs_{y}_dmax_{d}.pdf'.format(x=x, y=y, d=d_max), bbox_inches=\"tight\")\n",
    "    \n",
    "    #### OLS plots\n",
    "    \n",
    "    y_col = 'conn_frac'\n",
    "    columns_frac =  ['n_syn_soma', 'soma_y_um', 'soma_x_um', 'syn_net_non', 'ais_radius', 'size_mean_chc']\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, row_filter, y_col, columns_frac[::-1], conn_frac_color,\n",
    "                                          robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "    res_df.to_csv(plot_dir + '/ols_fit_{}_dmax_{}.csv'.format(y_col, d_max), index=False)\n",
    "    fig.savefig(plot_dir + '/ols_fit_{}_dmax_{}.pdf'.format(y_col, d_max), bbox_inches=\"tight\")\n",
    "\n",
    "    y_col = 'num_potential'\n",
    "    columns_pot = ['n_syn_soma', 'soma_y_um', 'soma_x_um', 'syn_net_non', 'ais_radius', 'size_mean_chc']\n",
    "    fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, row_filter, y_col, columns_pot[::-1], num_pot_color,\n",
    "                                          robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "    res_df.to_csv(plot_dir + '/ols_fit_{}_dmax_{}.csv'.format(y_col, d_max), index=False)\n",
    "    fig.savefig(plot_dir + '/ols_fit_{}_dmax_{}.pdf'.format(y_col, d_max), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "    if 'label' in arbor_ais_df.columns:\n",
    "        y_col = 'conn_frac'\n",
    "        columns_frac =  ['soma_synapses', 'soma_y_um', 'soma_x_um', 'syn_net_non', 'ais_radius', 'size_mean_chc']\n",
    "        fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, row_filter, y_col, columns_frac[::-1], conn_frac_color,\n",
    "                                              robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "        res_df.to_csv(plot_dir + '/ols_fit_soma_exact_{}_dmax_{}.csv'.format(y_col, d_max), index=False)\n",
    "        fig.savefig(plot_dir + '/ols_fit_soma_exact_{}_dmax_{}.pdf'.format(y_col, d_max), bbox_inches=\"tight\")\n",
    "\n",
    "        y_col = 'num_potential'\n",
    "        columns_pot = ['soma_synapses', 'soma_y_um', 'soma_x_um', 'syn_net_non', 'ais_radius', 'size_mean_chc']\n",
    "        fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, row_filter, y_col, columns_pot[::-1], num_pot_color,\n",
    "                                              robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "        res_df.to_csv(plot_dir + '/ols_fit_soma_exact_{}_dmax_{}.csv'.format(y_col, d_max), index=False)\n",
    "        fig.savefig(plot_dir + '/ols_fit_soma_exact_{}_dmax_{}.pdf'.format(y_col, d_max), bbox_inches=\"tight\")\n",
    "\n",
    "        #### Soma synapse density\n",
    "        y_col = 'conn_frac'\n",
    "        columns_frac =  ['soma_syn_density', 'soma_y_um', 'soma_x_um', 'syn_net_non', 'ais_radius', 'size_mean_chc']\n",
    "        fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, row_filter, y_col, columns_frac[::-1], conn_frac_color,\n",
    "                                              robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "        res_df.to_csv(plot_dir + '/ols_fit_soma_density_{}_dmax_{}.csv'.format(y_col, d_max), index=False)\n",
    "        fig.savefig(plot_dir + '/ols_fit_soma_density_{}_dmax_{}.pdf'.format(y_col, d_max), bbox_inches=\"tight\")\n",
    "\n",
    "        y_col = 'num_potential'\n",
    "        columns_pot = ['soma_syn_density', 'soma_y_um', 'soma_x_um', 'syn_net_non', 'ais_radius', 'size_mean_chc']\n",
    "        fig, ax, res_df = ols_analysis_single(arbor_ais_df_pot, row_filter, y_col, columns_pot[::-1], num_pot_color,\n",
    "                                              robust=use_robust, xticks=np.arange(-0.75,.76,0.25))\n",
    "        res_df.to_csv(plot_dir + '/ols_fit_soma_density_{}_dmax_{}.csv'.format(y_col, d_max), index=False)\n",
    "        fig.savefig(plot_dir + '/ols_fit_soma_density_{}_dmax_{}.pdf'.format(y_col, d_max), bbox_inches=\"tight\")\n",
    "\n",
    "    else:\n",
    "        print('No exact soma data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'ais_radius' in arbor_ais_df_pot.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_pup_df = pd.read_hdf(f'{base_dir}/notebooks/activity_df.h5', 'activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = AnalysisDataLink(dataset_name=dataset_name,\n",
    "                      sqlalchemy_database_uri=sql_database_uri_base,\n",
    "                      materialization_version=data_version,\n",
    "                      verbose=False)\n",
    "\n",
    "somav1_df = dl.query_cell_types('soma_valence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_pup_df2 = act_pup_df.merge(somav1_df[['id', 'pt_root_id']], left_on='soma_id', right_on='id', how='left').drop(columns=['id_x', 'id_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat_df = arbor_ais_df_use.merge(act_pup_df2.drop(columns=['syn_net_chc']), left_on='post_pt_root_id', right_on='pt_root_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "base_variables = [f'pca_{ii}' for ii in range(pca.n_components)]\n",
    "plot_label_lookup_ext = copy(plot_label_lookup)\n",
    "plot_label_lookup_ext['activity_during'] = 'activity_during'\n",
    "plot_label_lookup_ext['activity_diff'] = 'activity_diff'\n",
    "plot_label_lookup_ext['activity_outside'] = 'activity_outside'\n",
    "\n",
    "y_col = 'syn_net_chc'\n",
    "rel_variables = base_variables + ['activity_outside']\n",
    "fig, ax, res_df = ols_analysis_single(full_dat_df, full_dat_df['post_pt_root_id']>0,\n",
    "                                      y_col, rel_variables[::-1], chc_color, robust=False,\n",
    "                                      plot_label_lookup=plot_label_lookup_ext,\n",
    "                                      xticks=np.arange(-0.75,.76,0.25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relinds = full_dat_df['activity_diff']<0.1\n",
    "nan_pearsonr(full_dat_df['pca_2'][relinds], full_dat_df['activity_diff'][relinds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_lookup['pca_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='pca_1', x='activity_diff', data=full_dat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = base_dir \n",
    "pupil_data = f'{data_dir}/cell_pupil_metrics.csv'\n",
    "pupil_df = pd.read_csv(pupil_data, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "648518346349538387 in soma_func_df['pt_root_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_lookup_df = dl.query_cell_ids('functional_coregistration_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_lookup_df.query('func_id == 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df.query('func_id == 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_df.query('soma_id == 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df['func_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df = dl.query_cell_ids('functional_coregistration_lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df.query('func_id==10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df.query('pt_root_id==648518346349538384')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_df.query('pt_root_id==648518346349538384')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all( np.vstack(soma_func_df['pt_position'].values) == np.array([101597, 55229, 1412]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df.query('pt_root_id == 648518346349538384')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_fname = f'{data_dir}/con_onset_mean_activity.npy'\n",
    "dil_fname = f'{data_dir}/dil_onset_mean_activity.npy'\n",
    "\n",
    "run_on_fname = f'{data_dir}/run_onset_mean_activity.npy'\n",
    "run_off_fname = f'{data_dir}/run_offset_mean_activity.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_df['con_activity'] = [x for x in np.load(con_fname)]\n",
    "pupil_df['dil_activity'] = [x for x in np.load(dil_fname)]\n",
    "pupil_df['run_on_activity'] = [x for x in np.load(run_on_fname)]\n",
    "pupil_df['run_off_activity'] = [x for x in np.load(run_off_fname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['pt_root_id', 'soma_id',\n",
    "       'dj_soma_x', 'dj_soma_y', 'dj_soma_z',\n",
    "       'mean_firing_dil', 'mean_firing_con', 'dcp_index',\n",
    "       'mean_firing_dil.1', 'mean_firing_con.1', 'dcp_index.1',\n",
    "       'mean_firing_dil.2', 'mean_firing_con.2', 'dcp_index.2',\n",
    "       'mean_firing_dil.3', 'mean_firing_con.3', 'dcp_index.3',\n",
    "       'dil_activity', 'con_activity', 'run_on_activity', 'run_off_activity']\n",
    "pupil_df.rename(columns={'soma_x': 'dj_soma_x', \n",
    "                        'soma_y': 'dj_soma_y',\n",
    "                        'soma_z': 'dj_soma_z',},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = AnalysisDataLink(dataset_name=dataset_name,\n",
    "                      sqlalchemy_database_uri=sql_database_uri_base,\n",
    "                      materialization_version=data_version,\n",
    "                      verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df = dl.query_cell_ids('functional_coregistration_lookup')\n",
    "# soma_func_df = dl.query_cell_ids(soma_table)\n",
    "# soma_pupil_df = soma_func_df.merge(pupil_df, left_on='id', right_on='soma_id')\n",
    "\n",
    "soma_pupil_df = soma_func_df.merge(pupil_df, left_on='func_id', right_on='soma_id')\n",
    "\n",
    "soma_pupil_df[['dj_soma_x', 'dj_soma_y', 'dj_soma_z', 'pt_position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df = dl.query_cell_ids('functional_coregistration_lookup')\n",
    "# soma_func_df = dl.query_cell_ids('soma_valence_v2')\n",
    "# soma_pupil_df = soma_func_df.merge(pupil_df, left_on='id', right_on='soma_id')\n",
    "\n",
    "soma_pupil_df = soma_func_df.merge(pupil_df, left_on='func_id', right_on='soma_id')\n",
    "soma_pupil_df = soma_pupil_df[keep_columns]\n",
    "\n",
    "pupil_plus_df = arbor_ais_df_use.merge(soma_pupil_df, how='left', left_on='post_pt_root_id', right_on='pt_root_id')\n",
    "\n",
    "sns.lmplot(x='soma_y', y='dcp_index', data=pupil_plus_df, robust=True)\n",
    "\n",
    "syn_pupil_dat = pupil_plus_df[['syn_net_chc', 'mean_firing_con.2']].values\n",
    "rows_keep = ~ np.any(np.isnan(syn_pupil_dat), axis=1)\n",
    "syn_pupil_dat=syn_pupil_dat[rows_keep,:]\n",
    "\n",
    "stats.spearmanr(syn_pupil_dat[:,0], syn_pupil_dat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_func_df = dl.query_cell_ids('soma_valence_v2')\n",
    "soma_pupil_df = soma_func_df.merge(pupil_df, left_on='id', right_on='soma_id')\n",
    "\n",
    "soma_pupil_df = soma_pupil_df[keep_columns]\n",
    "\n",
    "pupil_plus_df = arbor_ais_df_use.merge(soma_pupil_df, how='left', left_on='post_pt_root_id', right_on='pt_root_id')\n",
    "\n",
    "sns.lmplot(x='soma_y', y='dcp_index', data=pupil_plus_df, robust=True)\n",
    "\n",
    "syn_pupil_dat = pupil_plus_df[['syn_net_chc', 'mean_firing_con.1']].values\n",
    "rows_keep = ~ np.any(np.isnan(syn_pupil_dat), axis=1)\n",
    "syn_pupil_dat=syn_pupil_dat[rows_keep,:]\n",
    "\n",
    "stats.spearmanr(syn_pupil_dat[:,0], syn_pupil_dat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot( x='mean_firing_dil.2', y='mean_firing_con.2', size='syn_net_chc', hue='syn_net_chc', data=pupil_plus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='soma_y', y='soma_id', data=pupil_plus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_variables = [f'pca_{ii}' for ii in range(pca.n_components)]\n",
    "plot_label_lookup_ext = copy(plot_label_lookup)\n",
    "plot_label_lookup_ext['dcp_index'] = 'dcp_index'\n",
    "plot_label_lookup_ext['corr'] = 'pupil_corr'\n",
    "\n",
    "y_col = 'dcp_index'\n",
    "rel_variables = ['syn_net_chc',  'soma_y_adj']\n",
    "fig, ax, res_df = ols_analysis_single(pupil_plus_df, pupil_plus_df['post_pt_root_id']>0, y_col, rel_variables[::-1], chc_color, robust=False, plot_label_lookup=plot_label_lookup_ext, xticks=np.arange(-0.75,.76,0.25))\n",
    "\n",
    "# if do_save:\n",
    "#     res_df.to_csv(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.csv'.format(y_col), index=False)\n",
    "#     fig.savefig(f'{plot_dir}/{ls_prefix[use_robust]}_fit_factor_analysis_{y_col}.pdf'.format(y_col), bbox_inches=\"tight\")\n",
    "#     residual_scatterplots(y_col, columns_chc, row_filter_true, arbor_ais_df_use, 'exact', plot_dir, plot_label_lookup=plot_label_lookup, robust=use_robust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(pupil_plus_df[inds_rel]['dcp_index'], pupil_plus_df[inds_rel]['pca_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4) )\n",
    "fig.set_facecolor('w')\n",
    "sns.scatterplot(y='corr', x='syn_net_chc', data=pupil_plus_df, color='k', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='dcp_index', y='syn_net_chc', data=pupil_plus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(y='dcp_index', x='syn_net_chc', data=pupil_plus_df.query('soma_y>40000'), scatter_kws={'color':'k'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_plus_df.soma_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jitterbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitterbar.jitterbar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_inds = pupil_plus_df['dcp_index']<np.nanmedian(pupil_plus_df['dcp_index'])\n",
    "high_inds = pupil_plus_df['dcp_index']>=np.nanmedian(pupil_plus_df['dcp_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'syn_net_chc'\n",
    "\n",
    "cutoff = np.nanmean(pupil_plus_df['dcp_index'])\n",
    "low_inds = pupil_plus_df['dcp_index']<=cutoff\n",
    "high_inds = pupil_plus_df['dcp_index']>cutoff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,3))\n",
    "jitterbar.jitterbar([pupil_plus_df[low_inds][y_col], pupil_plus_df[high_inds][y_col]],\n",
    "                    color=[[0,0,0], [0,0,0]], mode='mean', ax=ax, labels=['low dcp', 'high dcp'])\n",
    "ax.set_ylabel(y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(pupil_plus_df[high_inds][y_col], arbor_ais_df_use[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(pupil_plus_df['syn_net_chc'], pupil_plus_df['dcp_index'], nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.fisher_exact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcutoffs = np.arange(2,20)\n",
    "ycutoffs = np.arange(-0.2, 0.6, 0.05)\n",
    "table_pvalues = np.zeros((len(xcutoffs), len(ycutoffs)))\n",
    "for ii, xcutoff in enumerate(xcutoffs):\n",
    "    for jj, ycutoff in enumerate(ycutoffs):\n",
    "        inds_low = pupil_plus_df[y_col] < xcutoff\n",
    "        \n",
    "        low_data = pupil_plus_df[inds_low]['dcp_index']\n",
    "        low_data = low_data[~np.isnan(low_data)]\n",
    "\n",
    "        high_data = pupil_plus_df[~inds_low]['dcp_index']\n",
    "        high_data = high_data[~np.isnan(high_data)]\n",
    "        \n",
    "        count_low_low = np.sum(low_data < ycutoff)\n",
    "        count_low_high = np.sum(low_data >= ycutoff)\n",
    "        table_low = [count_low_low, count_low_high]\n",
    "        \n",
    "        count_high_low = np.sum(high_data < ycutoff)\n",
    "        count_high_high = np.sum(high_data >= ycutoff)\n",
    "        table_high = [count_high_low, count_high_high]\n",
    "\n",
    "        oddsratio, pv = stats.fisher_exact([table_low, table_high])\n",
    "        table_pvalues[ii, jj] = pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_rel = ~np.isnan(pupil_plus_df['corr'])\n",
    "xcutoff = np.nanmedian(pupil_plus_df[inds_rel]['corr'])\n",
    "ycutoff = np.nanmedian(pupil_plus_df[inds_rel]['syn_net_chc'])\n",
    "\n",
    "count_low_low = np.sum(pupil_plus_df[inds_rel].query(f'corr <= {xcutoff}')['syn_net_chc'] <= ycutoff)\n",
    "count_low_high = np.sum(pupil_plus_df[inds_rel].query(f'corr <= {xcutoff}')['syn_net_chc'] > ycutoff)\n",
    "count_high_low = np.sum(pupil_plus_df[inds_rel].query(f'corr > {xcutoff}')['syn_net_chc'] <= ycutoff)\n",
    "count_high_high = np.sum(pupil_plus_df[inds_rel].query(f'corr > {xcutoff}')['syn_net_chc'] > ycutoff)\n",
    "\n",
    "table_low = [count_low_low, count_low_high]\n",
    "table_high = [count_high_low, count_high_high]\n",
    "\n",
    "stats.fisher_exact([table_low, table_high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "sns.scatterplot(x='corr', y='syn_net_chc', data=pupil_plus_df[inds_rel], ax=ax)\n",
    "ax.hlines(ycutoff, -0.2, 0.25)\n",
    "ax.vlines(xcutoff, 0, 25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(pupil_plus_df[inds_rel]['dcp_index'], pupil_plus_df[inds_rel][''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='dcp_index', y='pca_2', data=pupil_plus_df[inds_rel])\n",
    "sns.scatterplot(np.zeros(len(arbor_ais_df_use)), arbor_ais_df_use['pca_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "ax.matshow(table_pvalues < 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(pupil_plus_df['dcp_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcutoffs = np.arange(-0.1, 0.333, 0.05)\n",
    "y_col = 'dcp_index'\n",
    "\n",
    "pvalues = []\n",
    "for xcutoff in xcutoffs:\n",
    "    inds_low = pupil_plus_df[y_col] < xcutoff\n",
    "    low_data = pupil_plus_df[inds_low]['syn_net_chc']\n",
    "    low_data = low_data[~np.isnan(low_data)]\n",
    "\n",
    "    inds_high = pupil_plus_df[y_col] > xcutoff\n",
    "    high_data = pupil_plus_df[inds_high]['syn_net_chc']\n",
    "    high_data = high_data[~np.isnan(high_data)]\n",
    "\n",
    "    out = stats.ttest_ind(low_data, high_data)\n",
    "    pvalues.append(out.pvalue)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))    \n",
    "ax.plot(xcutoffs, pvalues, 's-')\n",
    "ax.hlines(0.05, np.min(xcutoffs), np.max(xcutoffs),  linestyle='--')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('DCP Index Cutoff')\n",
    "ax.set_ylabel('p-value for mean chc syn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcutoffs = np.arange(2,20)\n",
    "y_col = 'syn_net_chc'\n",
    "\n",
    "pvalues = []\n",
    "for xcutoff in xcutoffs:\n",
    "    inds_low = pupil_plus_df[y_col] < xcutoff\n",
    "    low_data = pupil_plus_df[inds_low]['dcp_index']\n",
    "    low_data = low_data[~np.isnan(low_data)]\n",
    "\n",
    "    high_data = pupil_plus_df[~inds_low]['dcp_index']\n",
    "    high_data = high_data[~np.isnan(high_data)]\n",
    "\n",
    "    out = stats.ttest_ind(low_data, high_data)\n",
    "    pvalues.append(out.pvalue)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))    \n",
    "ax.plot(xcutoffs, pvalues, 's-')\n",
    "ax.hlines(0.05, np.min(xcutoffs), np.max(xcutoffs),  linestyle='--')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_plus_df[inds_low]['dcp_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='dcp_index', x='soma_y', data=pupil_plus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='corr', x='syn_net_chc', data=pupil_plus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_columns = [\n",
    " 'soma_synapses',\n",
    " 'soma_area',\n",
    " 'soma_syn_density',\n",
    " 'syn_net_non',\n",
    " 'ais_radius',\n",
    " 'soma_y_um',\n",
    " 'dcp_index',\n",
    " 'corr']\n",
    "\n",
    "extra_corr_matrix_columns = ['syn_net_chc']+corr_matrix_columns\n",
    "ais_item_data = pupil_plus_df[inds_rel][extra_corr_matrix_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.zeros((len(extra_corr_matrix_columns), len(extra_corr_matrix_columns)))\n",
    "corr_mat_p = np.zeros((len(extra_corr_matrix_columns), len(extra_corr_matrix_columns)))\n",
    "for ii in range(len(extra_corr_matrix_columns)):\n",
    "    for jj in range(len(extra_corr_matrix_columns)):\n",
    "        r, p = nan_pearsonr(pupil_plus_df[extra_corr_matrix_columns[ii]], pupil_plus_df[extra_corr_matrix_columns[jj]])\n",
    "        corr_mat[ii,jj] = r\n",
    "        corr_mat_p[ii,jj] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest\n",
    "is_sig, corr_p, _, _ = multitest.multipletests(corr_mat_p[np.tril_indices_from(corr_mat, k=-1)])\n",
    "tri_inds = np.tril_indices_from(corr_mat, k=-1)\n",
    "put_star = []\n",
    "for ii, jj, sig in zip(*tri_inds, is_sig):\n",
    "    if sig:\n",
    "        put_star.append([ii, jj])\n",
    "put_star = np.array(put_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_plot = True \n",
    "\n",
    "mask = np.zeros_like(corr_mat, dtype=np.bool)\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "\n",
    "cmap = sns.color_palette('RdBu', n_colors=31)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(corr_mat, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "ax.plot(put_star[:,0]+0.5, put_star[:,1]+0.5, 'k*')\n",
    "ax.set_yticks(np.arange(0.5, len(extra_corr_matrix_columns)-1+0.5))\n",
    "_=ax.set_yticklabels([plot_label_lookup_ext[x] for x in extra_corr_matrix_columns[:-1]], rotation=0)\n",
    "\n",
    "ax.set_xticks(np.arange(1.5, len(extra_corr_matrix_columns)+0.5))\n",
    "_=ax.set_xticklabels([plot_label_lookup_ext[x] for x in extra_corr_matrix_columns[1:]], rotation=45)\n",
    "ax.xaxis.tick_top()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_item_data = pupil_plus_df[inds_rel][corr_matrix_columns].fillna(0)\n",
    "Xdat = ais_item_data.values\n",
    "Xz = stats.zscore(Xdat, axis=0)\n",
    "\n",
    "# pca = FastICA(n_components=3, random_state=5010 )\n",
    "pca = FactorAnalysis(n_components=4)\n",
    "Xz_pca = pca.fit_transform(Xz)\n",
    "\n",
    "for ii in range(pca.n_components):\n",
    "    if pca.components_[ii,np.argmax(np.abs(pca.components_[ii,:]))] < 0:   # If the dominant component is negative\n",
    "        pca.components_[ii, :] = -1 * pca.components_[ii, :]\n",
    "        Xz_pca[:,ii] = -1 * Xz_pca[:,ii]\n",
    "\n",
    "for ii in range(pca.n_components):\n",
    "    fig, ax = plt.subplots(figsize=(1,2))\n",
    "    ax.barh(np.arange(pca.components_.shape[1]), pca.components_[ii,:], height=0.5, color='k')\n",
    "    ax.vlines(0, -1, 7, linewidth=1)\n",
    "    ax.set_ylim((-0.5, 7.5))\n",
    "    ax.set_yticks(np.arange(pca.components_.shape[1]))\n",
    "    ax.set_yticklabels([plot_label_lookup_ext[x] for x in corr_matrix_columns])\n",
    "    ax.invert_yaxis()\n",
    "    maxval=np.max(np.abs(pca.components_[ii,:]))\n",
    "    ax.set_xlim((-maxval, maxval))\n",
    "    ax.set_xticks((-maxval, 0, maxval))\n",
    "    ax.set_xticklabels((f'{-maxval:0.2f}', '0', f'{maxval:0.2f}'))\n",
    "    sns.despine(ax=ax, offset=5, trim=True)\n",
    "    ax.set_title(f'PC {ii}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "sns.scatterplot(x='corr', y='dcp_index', data=pupil_plus_df, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
